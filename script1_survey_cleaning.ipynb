{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling University of British Columbia Survey Data\n",
    "## A Particularly Spooky Halloween Dataset\n",
    "### James Davis\n",
    "Table of contents:\n",
    "* [Getting an overview of the data.](#overview)\n",
    "* [Checking the Internal ID column for duplicates.](#id_check)\n",
    "* [Cleaning age values.](#age_clean)\n",
    "* [Dropping unnecessary columns.](#col_drop)\n",
    "* [Combining the four media columns.](#media)\n",
    "* [Deleting abandoned responses.](#del_aban)\n",
    "* [Filling invalid categorical fields.](#inv_fields)\n",
    "* [Converting each of the three categories of opinion on each lolly to an integer.](#lolly_int)\n",
    "* [Standardising countries](#countries)\n",
    "* [Standardising states](#states)\n",
    "* ['Unpivoting' the responses.](#unpivot)\n",
    "* [Final checks and cleanup before saving output.](#output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Personal\\Education\\Programming\\Anaconda1\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "pwd = os.getcwd() # Helps with file management.\n",
    "survey_df = pd.read_excel(pwd + '\\data1_raw_survey_input.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview <a class=\"anchor\" id=\"overview\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internal ID</th>\n",
       "      <th>Q1: GOING OUT?</th>\n",
       "      <th>Q2: GENDER</th>\n",
       "      <th>Q3: AGE</th>\n",
       "      <th>Q4: COUNTRY</th>\n",
       "      <th>Q5: STATE, PROVINCE, COUNTY, ETC</th>\n",
       "      <th>Q6 | 100 Grand Bar</th>\n",
       "      <th>Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)</th>\n",
       "      <th>Q6 | Any full-sized candy bar</th>\n",
       "      <th>Q6 | Black Jacks</th>\n",
       "      <th>...</th>\n",
       "      <th>Q8: DESPAIR OTHER</th>\n",
       "      <th>Q9: OTHER COMMENTS</th>\n",
       "      <th>Q10: DRESS</th>\n",
       "      <th>Unnamed: 113</th>\n",
       "      <th>Q11: DAY</th>\n",
       "      <th>Q12: MEDIA [Daily Dish]</th>\n",
       "      <th>Q12: MEDIA [Science]</th>\n",
       "      <th>Q12: MEDIA [ESPN]</th>\n",
       "      <th>Q12: MEDIA [Yahoo]</th>\n",
       "      <th>Click Coordinates (x, y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90258773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90272821</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>USA</td>\n",
       "      <td>NM</td>\n",
       "      <td>MEH</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bottom line is Twix is really the only candy w...</td>\n",
       "      <td>White and gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(84, 25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90272829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>49</td>\n",
       "      <td>USA</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90272840</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>us</td>\n",
       "      <td>or</td>\n",
       "      <td>MEH</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Raisins can go to hell</td>\n",
       "      <td>White and gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(75, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90272841</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>usa</td>\n",
       "      <td>exton pa</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White and gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(70, 10)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Internal ID Q1: GOING OUT? Q2: GENDER Q3: AGE Q4: COUNTRY  \\\n",
       "0     90258773            NaN        NaN     NaN         NaN   \n",
       "1     90272821             No       Male      44        USA    \n",
       "2     90272829            NaN       Male      49         USA   \n",
       "3     90272840             No       Male      40          us   \n",
       "4     90272841             No       Male      23         usa   \n",
       "\n",
       "  Q5: STATE, PROVINCE, COUNTY, ETC Q6 | 100 Grand Bar  \\\n",
       "0                              NaN                NaN   \n",
       "1                               NM                MEH   \n",
       "2                         Virginia                NaN   \n",
       "3                               or                MEH   \n",
       "4                         exton pa                JOY   \n",
       "\n",
       "  Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)  \\\n",
       "0                                                NaN                                       \n",
       "1                                            DESPAIR                                       \n",
       "2                                                NaN                                       \n",
       "3                                            DESPAIR                                       \n",
       "4                                            DESPAIR                                       \n",
       "\n",
       "  Q6 | Any full-sized candy bar Q6 | Black Jacks  ... Q8: DESPAIR OTHER  \\\n",
       "0                           NaN              NaN  ...               NaN   \n",
       "1                           JOY              MEH  ...               NaN   \n",
       "2                           NaN              NaN  ...               NaN   \n",
       "3                           JOY              MEH  ...               NaN   \n",
       "4                           JOY          DESPAIR  ...               NaN   \n",
       "\n",
       "                                  Q9: OTHER COMMENTS      Q10: DRESS  \\\n",
       "0                                                NaN             NaN   \n",
       "1  Bottom line is Twix is really the only candy w...  White and gold   \n",
       "2                                                NaN             NaN   \n",
       "3                             Raisins can go to hell  White and gold   \n",
       "4                                                NaN  White and gold   \n",
       "\n",
       "  Unnamed: 113 Q11: DAY Q12: MEDIA [Daily Dish] Q12: MEDIA [Science]  \\\n",
       "0          NaN      NaN                     NaN                  NaN   \n",
       "1          NaN   Sunday                     NaN                  1.0   \n",
       "2          NaN      NaN                     NaN                  NaN   \n",
       "3          NaN   Sunday                     NaN                  1.0   \n",
       "4          NaN   Friday                     NaN                  1.0   \n",
       "\n",
       "  Q12: MEDIA [ESPN] Q12: MEDIA [Yahoo] Click Coordinates (x, y)  \n",
       "0               NaN                NaN                      NaN  \n",
       "1               NaN                NaN                 (84, 25)  \n",
       "2               NaN                NaN                      NaN  \n",
       "3               NaN                NaN                 (75, 23)  \n",
       "4               NaN                NaN                 (70, 10)  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 30\n",
    "survey_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Internal ID                   int64\n",
       "Q1: GOING OUT?               object\n",
       "Q2: GENDER                   object\n",
       "Q3: AGE                      object\n",
       "Q4: COUNTRY                  object\n",
       "                             ...   \n",
       "Q12: MEDIA [Daily Dish]     float64\n",
       "Q12: MEDIA [Science]        float64\n",
       "Q12: MEDIA [ESPN]           float64\n",
       "Q12: MEDIA [Yahoo]          float64\n",
       "Click Coordinates (x, y)     object\n",
       "Length: 120, dtype: object"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'll be worth converting all these once we've finished surgically alterting this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Duplicate Respondents <a class=\"anchor\" id=\"id_check\"></a>\n",
    "Never trust an assumption about your data until you've verified it, especially when it's this zany!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total IDs: 2460\n",
      "Unique IDs: 2460\n"
     ]
    }
   ],
   "source": [
    "print(f'Total IDs: {len(survey_df[\"Internal ID\"])}')\n",
    "print(f'Unique IDs: {survey_df[\"Internal ID\"].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Age Values <a class=\"anchor\" id=\"age_clean\"></a>\n",
    "The data contain a few... aberrant responses.\n",
    "\n",
    "Note: I'll be making a few copies throughout so it's easier to track my progress at different stages and roll back mistakes. \n",
    "The tradeoff is storing a bunch of variables, but for a project of this size it's not a real concern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_agedrop = survey_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values: 84\n",
      "Non-numeric values: 24\n",
      "Total values: 2460\n"
     ]
    }
   ],
   "source": [
    "print(f'Null values: {survey_df_agedrop[\"Q3: AGE\"].isna().sum()}')\n",
    "print(f'Non-numeric values: {len([age for age in survey_df_agedrop[\"Q3: AGE\"] if isinstance(age, str) == True])}')\n",
    "print(f'Total values: {len(survey_df_agedrop[\"Q3: AGE\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We therefore need 108 cells to be 0 whilst preserving the int64 dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0       108\n",
       "40.0       92\n",
       "34.0       90\n",
       "37.0       89\n",
       "43.0       86\n",
       "         ... \n",
       "88.0        1\n",
       "312.0       1\n",
       "70.5        1\n",
       "99.0        1\n",
       "1000.0      1\n",
       "Name: Q3: AGE, Length: 84, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_agedrop['Q3: AGE'] = pd.to_numeric(survey_df_agedrop['Q3: AGE'], errors='coerce')\n",
    "survey_df_agedrop.replace(np.nan, 0, inplace=True)\n",
    "survey_df_agedrop.astype({'Q3: AGE': 'int64'}, errors='ignore', copy=False)\n",
    "survey_df_agedrop['Q3: AGE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values: 0\n",
      "Non-numeric values: 0\n",
      "2460\n"
     ]
    }
   ],
   "source": [
    "print(f'Null values: {survey_df_agedrop[\"Q3: AGE\"].isna().sum()}')\n",
    "print(f'Non-numeric values: {len([age for age in survey_df_agedrop[\"Q3: AGE\"] if isinstance(age, str) == True])}')\n",
    "print(len(survey_df_agedrop['Q3: AGE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all the rubbish has been swept out, time for a sense-check. It's very unlikely that a 300-year-old is taking this survey. I'm going to assume anyone aged 90 or over is just trying to be funny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dubious ages: 8\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of dubious ages: {len([age for age in survey_df_agedrop[\"Q3: AGE\"] if age >= 90])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_sensecheck = survey_df_agedrop.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dubious ages: 0\n"
     ]
    }
   ],
   "source": [
    "survey_df_sensecheck[\"Q3: AGE\"] = [int(age) if age < 90 else 0 for age in survey_df_sensecheck[\"Q3: AGE\"]]\n",
    "print(f'Number of dubious ages: {len([age for age in survey_df_sensecheck[\"Q3: AGE\"] if age >= 90])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd also like to exclude a few exceptionally young ages. Halloween lollies are the domain of kids, but I'd say it's highly unlikely any kid under three is capable of coherent opinions. If you were an opinionated two-year-old, don't hesitate to refrain from letting me know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of far-too-young ages: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of far-too-young ages: {len([age for age in survey_df_sensecheck[\"Q3: AGE\"] if age <= 2 and age != 0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of far-too-young ages: 0\n"
     ]
    }
   ],
   "source": [
    "survey_df_sensecheck[\"Q3: AGE\"] = [int(age) if age > 2 else 0 for age in survey_df_sensecheck[\"Q3: AGE\"]]\n",
    "print(f'Number of far-too-young ages: {len([age for age in survey_df_sensecheck[\"Q3: AGE\"] if age <= 2 and age != 0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish up, I'm going to replace all 0s with the median age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41    191\n",
       "40     92\n",
       "34     90\n",
       "37     89\n",
       "43     86\n",
       "     ... \n",
       "8       2\n",
       "4       1\n",
       "88      1\n",
       "74      1\n",
       "77      1\n",
       "Name: Q3: AGE, Length: 74, dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_sensecheck[\"Q3: AGE\"] = [age if age > 0 else survey_df_sensecheck[\"Q3: AGE\"].median() for age in survey_df_sensecheck[\"Q3: AGE\"]]\n",
    "survey_df_sensecheck[\"Q3: AGE\"] = survey_df_sensecheck[\"Q3: AGE\"].astype('int64')\n",
    "survey_df_sensecheck[\"Q3: AGE\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Unneeded Columns <a class=\"anchor\" id=\"col_drop\"></a>\n",
    "There are several suspect columns in this dataset that are unlikely to be valuable without the aid of quantum computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Internal ID', 'Q1: GOING OUT?', 'Q2: GENDER', 'Q3: AGE', 'Q4: COUNTRY',\n",
       "       'Q5: STATE, PROVINCE, COUNTY, ETC', 'Q6 | 100 Grand Bar',\n",
       "       'Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)',\n",
       "       'Q6 | Any full-sized candy bar', 'Q6 | Black Jacks',\n",
       "       ...\n",
       "       'Q8: DESPAIR OTHER', 'Q9: OTHER COMMENTS', 'Q10: DRESS', 'Unnamed: 113',\n",
       "       'Q11: DAY', 'Q12: MEDIA [Daily Dish]', 'Q12: MEDIA [Science]',\n",
       "       'Q12: MEDIA [ESPN]', 'Q12: MEDIA [Yahoo]', 'Click Coordinates (x, y)'],\n",
       "      dtype='object', length=120)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_sensecheck.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                          2451\n",
       "dress (https://survey.ubc.ca/media/assets/user/14372/storage/dress.png)       9\n",
       "Name: Unnamed: 113, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_sensecheck['Unnamed: 113'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While some of these columns are just strictly useless, others could conceivably be useful. For instance, knowing the day someone completed the survey could be part of a meta study on when people are most likely to do surveys. But that's not very useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Internal ID', 'Q1: GOING OUT?', 'Q2: GENDER', 'Q3: AGE', 'Q4: COUNTRY',\n",
       "       'Q5: STATE, PROVINCE, COUNTY, ETC', 'Q6 | 100 Grand Bar',\n",
       "       'Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)',\n",
       "       'Q6 | Any full-sized candy bar', 'Q6 | Black Jacks',\n",
       "       ...\n",
       "       'Q6 | Vials of pure high fructose corn syrup, for main-lining into your vein',\n",
       "       'Q6 | Vicodin', 'Q6 | Whatchamacallit Bars', 'Q6 | White Bread',\n",
       "       'Q6 | Whole Wheat anything', 'Q6 | York Peppermint Patties',\n",
       "       'Q12: MEDIA [Daily Dish]', 'Q12: MEDIA [Science]', 'Q12: MEDIA [ESPN]',\n",
       "       'Q12: MEDIA [Yahoo]'],\n",
       "      dtype='object', length=113)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_coldrops = survey_df_sensecheck.copy()\n",
    "survey_df_coldrops.drop(columns=['Q7: JOY OTHER', 'Q8: DESPAIR OTHER', 'Q9: OTHER COMMENTS', 'Unnamed: 113', 'Q10: DRESS', 'Click Coordinates (x, y)', 'Q11: DAY'], inplace=True)\n",
    "survey_df_coldrops.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Media Columns <a class=\"anchor\" id=\"media\"></a>\n",
    "The media columns are a highly-unrelated portion of the survey where respondents are presented with four mobile homepages and asked to honestly select which one they'd click on. \n",
    "\n",
    "The reason we're keeping this and not the dress, click coordinates or day columns is because it looks like a neat little challenge. Sue me.\n",
    "\n",
    "I want a single media column containing a categorical variable for each of the media organisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_media = survey_df_coldrops.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm thinking I handle this via the following process:\n",
    "1. Change media column values to 1 - 4, where 2 would be 'Science', 3 would be 'ESPN' etc.\n",
    "2. Collapse all values into new MEDIA column.\n",
    "3. Convert values 1 - 4 into 'Daily Dish' - 'Yahoo' respectively.\n",
    "4. Drop all four original media columns.\n",
    "\n",
    "If any of these clowns have selected multiple answers, we'll know soon enough!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_changer(data, numadd):\n",
    "    result = [i + numadd if i > 0 else i for i in data]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_data = ['Q12: MEDIA [Daily Dish]', 'Q12: MEDIA [Science]', 'Q12: MEDIA [ESPN]', 'Q12: MEDIA [Yahoo]']\n",
    "\n",
    "for ind, media_col in enumerate(media_data):\n",
    "    survey_df_media[media_col] = num_changer(survey_df_media[media_col], ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q12: MEDIA [Daily Dish]</th>\n",
       "      <th>Q12: MEDIA [Science]</th>\n",
       "      <th>Q12: MEDIA [ESPN]</th>\n",
       "      <th>Q12: MEDIA [Yahoo]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q12: MEDIA [Daily Dish]  Q12: MEDIA [Science]  Q12: MEDIA [ESPN]  \\\n",
       "1770                      0.0                   0.0                0.0   \n",
       "1771                      0.0                   0.0                0.0   \n",
       "1772                      0.0                   0.0                0.0   \n",
       "1773                      0.0                   2.0                0.0   \n",
       "1774                      0.0                   2.0                0.0   \n",
       "1775                      0.0                   0.0                0.0   \n",
       "1776                      0.0                   2.0                0.0   \n",
       "1777                      0.0                   0.0                0.0   \n",
       "1778                      0.0                   2.0                0.0   \n",
       "1779                      0.0                   2.0                0.0   \n",
       "1780                      0.0                   0.0                0.0   \n",
       "1781                      0.0                   0.0                0.0   \n",
       "1782                      0.0                   0.0                0.0   \n",
       "1783                      0.0                   2.0                0.0   \n",
       "1784                      1.0                   0.0                0.0   \n",
       "1785                      0.0                   0.0                0.0   \n",
       "1786                      0.0                   2.0                0.0   \n",
       "1787                      0.0                   0.0                3.0   \n",
       "1788                      0.0                   0.0                0.0   \n",
       "1789                      0.0                   0.0                0.0   \n",
       "1790                      0.0                   2.0                0.0   \n",
       "\n",
       "      Q12: MEDIA [Yahoo]  \n",
       "1770                 0.0  \n",
       "1771                 0.0  \n",
       "1772                 4.0  \n",
       "1773                 0.0  \n",
       "1774                 0.0  \n",
       "1775                 0.0  \n",
       "1776                 0.0  \n",
       "1777                 0.0  \n",
       "1778                 0.0  \n",
       "1779                 0.0  \n",
       "1780                 0.0  \n",
       "1781                 0.0  \n",
       "1782                 0.0  \n",
       "1783                 0.0  \n",
       "1784                 0.0  \n",
       "1785                 0.0  \n",
       "1786                 0.0  \n",
       "1787                 0.0  \n",
       "1788                 0.0  \n",
       "1789                 0.0  \n",
       "1790                 0.0  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_media[media_data].loc[1770:1790] # I've taken this oddball slice because it contains responses in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1770    0.0\n",
       "1771    0.0\n",
       "1772    4.0\n",
       "1773    2.0\n",
       "1774    2.0\n",
       "1775    0.0\n",
       "1776    2.0\n",
       "1777    0.0\n",
       "1778    2.0\n",
       "1779    2.0\n",
       "1780    0.0\n",
       "1781    0.0\n",
       "1782    0.0\n",
       "1783    2.0\n",
       "1784    1.0\n",
       "1785    0.0\n",
       "1786    2.0\n",
       "1787    3.0\n",
       "1788    0.0\n",
       "1789    0.0\n",
       "1790    2.0\n",
       "Name: Q12: MEDIA, dtype: float64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_media['Q12: MEDIA'] = survey_df_media[media_data].sum(axis=1)\n",
    "survey_df_media['Q12: MEDIA'].loc[1770:1790]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1770          None\n",
       "1771          None\n",
       "1772         Yahoo\n",
       "1773       Science\n",
       "1774       Science\n",
       "1775          None\n",
       "1776       Science\n",
       "1777          None\n",
       "1778       Science\n",
       "1779       Science\n",
       "1780          None\n",
       "1781          None\n",
       "1782          None\n",
       "1783       Science\n",
       "1784    Daily Dish\n",
       "1785          None\n",
       "1786       Science\n",
       "1787          ESPN\n",
       "1788          None\n",
       "1789          None\n",
       "1790       Science\n",
       "Name: Q12: MEDIA, dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valuedict = {0: 'None',\n",
    "             1: 'Daily Dish',\n",
    "             2: 'Science',\n",
    "             3: 'ESPN',\n",
    "             4: 'Yahoo'}\n",
    "\n",
    "for key, value in valuedict.items():\n",
    "    for ind, media in enumerate(survey_df_media['Q12: MEDIA']):\n",
    "        if media == key:\n",
    "            survey_df_media.loc[ind, 'Q12: MEDIA'] = value\n",
    "\n",
    "survey_df_media.loc[1770:1790, 'Q12: MEDIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_media.drop(columns=media_data, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Science       1362\n",
       "None           847\n",
       "ESPN            99\n",
       "Daily Dish      85\n",
       "Yahoo           67\n",
       "Name: Q12: MEDIA, dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_media['Q12: MEDIA'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Abandoned Responses <a class=\"anchor\" id=\"del_aban\"></a>\n",
    "Some users opened the survey, but immediately closed the tab. We'll delete these responses by scanning each row for responses of '0' in all main question fields, getting the index of each, then dropping them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 6, 10, 18]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowdrops = (survey_df_media.iloc[:, 6:111:1] == 0) # Returns a dataframe of True/ False values, where True = 0.\n",
    "dropindex = rowdrops.index[rowdrops['Q6 | 100 Grand Bar']].tolist()\n",
    "dropindex[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_abandrops = survey_df_media.copy()\n",
    "survey_df_abandrops.drop(dropindex, inplace=True)\n",
    "survey_df_abandrops.reset_index(inplace=True)\n",
    "survey_df_abandrops.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internal ID</th>\n",
       "      <th>Q1: GOING OUT?</th>\n",
       "      <th>Q2: GENDER</th>\n",
       "      <th>Q3: AGE</th>\n",
       "      <th>Q4: COUNTRY</th>\n",
       "      <th>Q5: STATE, PROVINCE, COUNTY, ETC</th>\n",
       "      <th>Q6 | 100 Grand Bar</th>\n",
       "      <th>Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)</th>\n",
       "      <th>Q6 | Any full-sized candy bar</th>\n",
       "      <th>Q6 | Black Jacks</th>\n",
       "      <th>...</th>\n",
       "      <th>Q6 | Tolberone something or other</th>\n",
       "      <th>Q6 | Trail Mix</th>\n",
       "      <th>Q6 | Twix</th>\n",
       "      <th>Q6 | Vials of pure high fructose corn syrup, for main-lining into your vein</th>\n",
       "      <th>Q6 | Vicodin</th>\n",
       "      <th>Q6 | Whatchamacallit Bars</th>\n",
       "      <th>Q6 | White Bread</th>\n",
       "      <th>Q6 | Whole Wheat anything</th>\n",
       "      <th>Q6 | York Peppermint Patties</th>\n",
       "      <th>Q12: MEDIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90272821</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>USA</td>\n",
       "      <td>NM</td>\n",
       "      <td>MEH</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>...</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90272840</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>us</td>\n",
       "      <td>or</td>\n",
       "      <td>MEH</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>...</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90272841</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>usa</td>\n",
       "      <td>exton pa</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>...</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>JOY</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90272852</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90272854</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>canada</td>\n",
       "      <td>ontario</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>...</td>\n",
       "      <td>MEH</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Internal ID Q1: GOING OUT? Q2: GENDER  Q3: AGE Q4: COUNTRY  \\\n",
       "0     90272821             No       Male       44        USA    \n",
       "1     90272840             No       Male       40          us   \n",
       "2     90272841             No       Male       23         usa   \n",
       "3     90272852             No       Male       41           0   \n",
       "4     90272854             No       Male       33      canada   \n",
       "\n",
       "  Q5: STATE, PROVINCE, COUNTY, ETC Q6 | 100 Grand Bar  \\\n",
       "0                               NM                MEH   \n",
       "1                               or                MEH   \n",
       "2                         exton pa                JOY   \n",
       "3                                0                JOY   \n",
       "4                          ontario                JOY   \n",
       "\n",
       "  Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)  \\\n",
       "0                                            DESPAIR                                       \n",
       "1                                            DESPAIR                                       \n",
       "2                                            DESPAIR                                       \n",
       "3                                            DESPAIR                                       \n",
       "4                                            DESPAIR                                       \n",
       "\n",
       "  Q6 | Any full-sized candy bar Q6 | Black Jacks  ...  \\\n",
       "0                           JOY              MEH  ...   \n",
       "1                           JOY              MEH  ...   \n",
       "2                           JOY          DESPAIR  ...   \n",
       "3                           JOY                0  ...   \n",
       "4                           JOY          DESPAIR  ...   \n",
       "\n",
       "  Q6 | Tolberone something or other Q6 | Trail Mix Q6 | Twix  \\\n",
       "0                               JOY        DESPAIR       JOY   \n",
       "1                               JOY            MEH       JOY   \n",
       "2                               JOY        DESPAIR       JOY   \n",
       "3                               JOY            MEH       JOY   \n",
       "4                               MEH        DESPAIR       JOY   \n",
       "\n",
       "  Q6 | Vials of pure high fructose corn syrup, for main-lining into your vein  \\\n",
       "0                                            DESPAIR                            \n",
       "1                                            DESPAIR                            \n",
       "2                                                MEH                            \n",
       "3                                            DESPAIR                            \n",
       "4                                                JOY                            \n",
       "\n",
       "  Q6 | Vicodin Q6 | Whatchamacallit Bars Q6 | White Bread  \\\n",
       "0      DESPAIR                   DESPAIR          DESPAIR   \n",
       "1          JOY                       JOY          DESPAIR   \n",
       "2          JOY                       JOY          DESPAIR   \n",
       "3      DESPAIR                       JOY          DESPAIR   \n",
       "4          MEH                   DESPAIR          DESPAIR   \n",
       "\n",
       "  Q6 | Whole Wheat anything Q6 | York Peppermint Patties Q12: MEDIA  \n",
       "0                   DESPAIR                      DESPAIR    Science  \n",
       "1                   DESPAIR                      DESPAIR    Science  \n",
       "2                   DESPAIR                          JOY    Science  \n",
       "3                   DESPAIR                          JOY    Science  \n",
       "4                   DESPAIR                      DESPAIR    Science  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_abandrops.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling Invalid Categorical Fields <a class=\"anchor\" id=\"inv_fields\"></a>\n",
    "There are only two valid choices ('Yes' and 'No'). I'm going to assume any response of 0 means they'd rather not say. This makes it consistent with the gender field, but even that has a similar issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1: GOING OUT?  Q2: GENDER        \n",
       "No              Male                  860\n",
       "                Female                493\n",
       "Yes             Male                  137\n",
       "                Female                 82\n",
       "No              I'd rather not say     48\n",
       "0               Male                   44\n",
       "No              Other                  18\n",
       "0               Female                  8\n",
       "Yes             I'd rather not say      8\n",
       "0               0                       4\n",
       "                I'd rather not say      4\n",
       "No              0                       3\n",
       "Yes             Other                   3\n",
       "0               Other                   1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_abandrops[['Q1: GOING OUT?', 'Q2: GENDER']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "problemcols = ['Q1: GOING OUT?', 'Q2: GENDER']\n",
    "\n",
    "for column in problemcols:\n",
    "    survey_df_abandrops[column] = [answer if answer != 0 else \"I'd rather not say\" for answer in survey_df_abandrops[column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1: GOING OUT?      Q2: GENDER        \n",
       "No                  Male                  860\n",
       "                    Female                493\n",
       "Yes                 Male                  137\n",
       "                    Female                 82\n",
       "No                  I'd rather not say     51\n",
       "I'd rather not say  Male                   44\n",
       "No                  Other                  18\n",
       "I'd rather not say  Female                  8\n",
       "                    I'd rather not say      8\n",
       "Yes                 I'd rather not say      8\n",
       "                    Other                   3\n",
       "I'd rather not say  Other                   1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_abandrops[['Q1: GOING OUT?', 'Q2: GENDER']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Lolly Categories <a class=\"anchor\" id=\"lolly_int\"></a>\n",
    "'Despair', 'Meh' and 'Joy' are reasonably functional, but if I were hired to clean this data set knowing there'd be further exploration, I'd want a slightly better way of scoring and aggregating this information. Just having them as integers seems like a solid idea. We can use some of the tricks employed earlier to convert these values to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_cats = survey_df_abandrops.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoredict = {'DESPAIR': 1,\n",
    "             'MEH': 2,\n",
    "             'JOY': 3}\n",
    "\n",
    "for column in survey_df_cats:\n",
    "    for key, value in scoredict.items():\n",
    "        survey_df_cats[column] = [answer if key != answer else value for answer in survey_df_cats[column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internal ID</th>\n",
       "      <th>Q1: GOING OUT?</th>\n",
       "      <th>Q2: GENDER</th>\n",
       "      <th>Q3: AGE</th>\n",
       "      <th>Q4: COUNTRY</th>\n",
       "      <th>Q5: STATE, PROVINCE, COUNTY, ETC</th>\n",
       "      <th>Q6 | 100 Grand Bar</th>\n",
       "      <th>Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)</th>\n",
       "      <th>Q6 | Any full-sized candy bar</th>\n",
       "      <th>Q6 | Black Jacks</th>\n",
       "      <th>...</th>\n",
       "      <th>Q6 | Tolberone something or other</th>\n",
       "      <th>Q6 | Trail Mix</th>\n",
       "      <th>Q6 | Twix</th>\n",
       "      <th>Q6 | Vials of pure high fructose corn syrup, for main-lining into your vein</th>\n",
       "      <th>Q6 | Vicodin</th>\n",
       "      <th>Q6 | Whatchamacallit Bars</th>\n",
       "      <th>Q6 | White Bread</th>\n",
       "      <th>Q6 | Whole Wheat anything</th>\n",
       "      <th>Q6 | York Peppermint Patties</th>\n",
       "      <th>Q12: MEDIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90272821</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>USA</td>\n",
       "      <td>NM</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90272840</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>us</td>\n",
       "      <td>or</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90272841</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>usa</td>\n",
       "      <td>exton pa</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90272852</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90272854</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>canada</td>\n",
       "      <td>ontario</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90272858</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>90272859</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>53</td>\n",
       "      <td>Us</td>\n",
       "      <td>Wa</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>90272865</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>56</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90272866</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>64</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90272867</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>43</td>\n",
       "      <td>Murica</td>\n",
       "      <td>California</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Internal ID Q1: GOING OUT? Q2: GENDER  Q3: AGE Q4: COUNTRY  \\\n",
       "0     90272821             No       Male       44        USA    \n",
       "1     90272840             No       Male       40          us   \n",
       "2     90272841             No       Male       23         usa   \n",
       "3     90272852             No       Male       41           0   \n",
       "4     90272854             No       Male       33      canada   \n",
       "5     90272858             No       Male       40      Canada   \n",
       "6     90272859             No     Female       53          Us   \n",
       "7     90272865             No       Male       56      Canada   \n",
       "8     90272866             No       Male       64          US   \n",
       "9     90272867            Yes       Male       43      Murica   \n",
       "\n",
       "  Q5: STATE, PROVINCE, COUNTY, ETC  Q6 | 100 Grand Bar  \\\n",
       "0                               NM                   2   \n",
       "1                               or                   2   \n",
       "2                         exton pa                   3   \n",
       "3                                0                   3   \n",
       "4                          ontario                   3   \n",
       "5                          Ontario                   3   \n",
       "6                               Wa                   2   \n",
       "7                           Quebec                   3   \n",
       "8                               NY                   2   \n",
       "9                       California                   3   \n",
       "\n",
       "   Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)  \\\n",
       "0                                                  1                                        \n",
       "1                                                  1                                        \n",
       "2                                                  1                                        \n",
       "3                                                  1                                        \n",
       "4                                                  1                                        \n",
       "5                                                  1                                        \n",
       "6                                                  1                                        \n",
       "7                                                  2                                        \n",
       "8                                                  2                                        \n",
       "9                                                  1                                        \n",
       "\n",
       "   Q6 | Any full-sized candy bar  Q6 | Black Jacks  ...  \\\n",
       "0                              3                 2  ...   \n",
       "1                              3                 2  ...   \n",
       "2                              3                 1  ...   \n",
       "3                              3                 0  ...   \n",
       "4                              3                 1  ...   \n",
       "5                              3                 2  ...   \n",
       "6                              3                 2  ...   \n",
       "7                              3                 2  ...   \n",
       "8                              3                 2  ...   \n",
       "9                              3                 2  ...   \n",
       "\n",
       "   Q6 | Tolberone something or other  Q6 | Trail Mix  Q6 | Twix  \\\n",
       "0                                  3               1          3   \n",
       "1                                  3               2          3   \n",
       "2                                  3               1          3   \n",
       "3                                  3               2          3   \n",
       "4                                  2               1          3   \n",
       "5                                  3               1          3   \n",
       "6                                  3               2          3   \n",
       "7                                  3               2          2   \n",
       "8                                  3               1          2   \n",
       "9                                  3               1          3   \n",
       "\n",
       "   Q6 | Vials of pure high fructose corn syrup, for main-lining into your vein  \\\n",
       "0                                                  1                             \n",
       "1                                                  1                             \n",
       "2                                                  2                             \n",
       "3                                                  1                             \n",
       "4                                                  3                             \n",
       "5                                                  2                             \n",
       "6                                                  1                             \n",
       "7                                                  1                             \n",
       "8                                                  3                             \n",
       "9                                                  1                             \n",
       "\n",
       "   Q6 | Vicodin  Q6 | Whatchamacallit Bars  Q6 | White Bread  \\\n",
       "0             1                          1                 1   \n",
       "1             3                          3                 1   \n",
       "2             3                          3                 1   \n",
       "3             1                          3                 1   \n",
       "4             2                          1                 1   \n",
       "5             1                          2                 1   \n",
       "6             1                          2                 1   \n",
       "7             2                          2                 3   \n",
       "8             3                          1                 1   \n",
       "9             1                          3                 1   \n",
       "\n",
       "   Q6 | Whole Wheat anything  Q6 | York Peppermint Patties  Q12: MEDIA  \n",
       "0                          1                             1     Science  \n",
       "1                          1                             1     Science  \n",
       "2                          1                             3     Science  \n",
       "3                          1                             3     Science  \n",
       "4                          1                             1     Science  \n",
       "5                          1                             1     Science  \n",
       "6                          1                             2     Science  \n",
       "7                          1                             2     Science  \n",
       "8                          1                             2     Science  \n",
       "9                          1                             3     Science  \n",
       "\n",
       "[10 rows x 110 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_cats.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Country Fields <a class=\"anchor\" id=\"countries\"></a>\n",
    "Now for a real challenge! These fields are absolutely abyssmal, filled with inconsistent capitalisation, abbreviations and colloquialisms (such as 'Murica' or 'Merica'). This means we can't just throw a dictionary at it. Let's start with the country field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USA              515\n",
       "United States    379\n",
       "usa              158\n",
       "Canada           104\n",
       "US                98\n",
       "                ... \n",
       "Canae              1\n",
       "USSA               1\n",
       "Narnia             1\n",
       "United Statss      1\n",
       "'merica            1\n",
       "Name: Q4: COUNTRY, Length: 95, dtype: int64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_cats['Q4: COUNTRY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes! OK, Here's the current plan:\n",
    "1. Make everything upper case to cut a few inconsistencies in a broad sweep.\n",
    "2. Cut all punctuation and spaces from each country.\n",
    "3. Paste in a dictionary of ISO3166 country codes. Source: https://gist.github.com/carlopires/1261951/d13ca7320a6abcd4b0aa800d351a31b54cefdff4\n",
    "4. Make the dictionary all uppercase.\n",
    "5. Remove all spaces from existing dictionary values.\n",
    "6. Append other common terms to dictionary values (eg 'US').\n",
    "7. Loop through the dictionary and replace each value with ISO country codes, taking care to use '==' instead of 'in' to account for cases where new values exist in other countries (eg 'US' can be found in the word 'AUSTRALIA', so we need an exact match).\n",
    "8. Celebrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_countryfix = survey_df_cats.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "survey_df_countryfix['Q4: COUNTRY'] = [str(country).upper() for country in survey_df_countryfix['Q4: COUNTRY']]\n",
    "\n",
    "for ind, country in enumerate(survey_df_countryfix['Q4: COUNTRY']):\n",
    "    survey_df_countryfix.loc[ind, 'Q4: COUNTRY'] = ''.join([char.replace(' ', '') for char in survey_df_countryfix['Q4: COUNTRY'].iloc[ind] if char not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data2_isodict import ISO3166\n",
    "\n",
    "countrydict = ISO3166.copy()\n",
    "sanitised_countries = [str(country).upper().replace(' ', '') for country in countrydict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, key in enumerate(countrydict.keys()):\n",
    "    countrydict[key] = sanitised_countries[ind]\n",
    "\n",
    "# Given the data is static, I don't mind manually updating the dictionary with a few synonyms it missed.\n",
    "countrydict['US'] = ['UNITEDSTATESOFAMERICA', 'UNITEDSTATES', 'USA', 'US', 'THEUNITEDSTATES', 'AMERICA']\n",
    "countrydict['GB'] = ['SCOTLAND', 'UK', 'UNITEDKINGDOM']\n",
    "countrydict['KR'] = ['SOUTHKOREA', 'REPUBLICOFSOUTHKOREA', 'KOREA']\n",
    "countrydict['AE'] = 'UAE'\n",
    "countrydict['TW'] = ['TAIWANPROVINCEOFCHINA', 'TAIWAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNITEDSTATESOFAMERICA',\n",
       " 'UNITEDSTATES',\n",
       " 'USA',\n",
       " 'US',\n",
       " 'THEUNITEDSTATES',\n",
       " 'AMERICA']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countrydict['US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, country in enumerate(survey_df_countryfix['Q4: COUNTRY']):\n",
    "    for key, values in countrydict.items():\n",
    "        if isinstance(values, list) == True:\n",
    "            for value in values:\n",
    "                if value == country:\n",
    "                    survey_df_countryfix.loc[ind, 'Q4: COUNTRY'] = key\n",
    "        else:\n",
    "            if values == country:\n",
    "                survey_df_countryfix.loc[ind, 'Q4: COUNTRY'] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US               1475\n",
       "CA                129\n",
       "0                  20\n",
       "GB                 15\n",
       "DE                  5\n",
       "                 ... \n",
       "ENDLAND             1\n",
       "NORTHCAROLINA       1\n",
       "CR                  1\n",
       "UNITEDSTAES         1\n",
       "GR                  1\n",
       "Name: Q4: COUNTRY, Length: 59, dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_countryfix['Q4: COUNTRY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed ISO conversions: 41\n",
      "Successful ISO conversions: 1651\n",
      "2.48% fail rate.\n"
     ]
    }
   ],
   "source": [
    "failures = len([country for country in survey_df_countryfix['Q4: COUNTRY'] if len(country) > 2])\n",
    "successes = len([country for country in survey_df_countryfix['Q4: COUNTRY'] if len(country) == 2])\n",
    "\n",
    "print(f\"Failed ISO conversions: {failures}\")\n",
    "print(f\"Successful ISO conversions: {successes}\")\n",
    "print(f\"{round((failures/ successes) * 100, 2)}% fail rate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decent! Given this is a static data set that won't be run again, I'm OK with having slapped a variety of synonyms into a dictionary.\n",
    "\n",
    "Let's now get the index of each trouble row and replace each one with 'US', because that has the highest likelihood of being correct given Americans are vastly overrepresented in the results already. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrydrop = [ind for ind, country in enumerate(survey_df_countryfix['Q4: COUNTRY']) if len(country) > 2 or len(country) < 2]\n",
    "survey_df_countryfix['Q4: COUNTRY'] = survey_df_countryfix['Q4: COUNTRY'].drop(countrydrop)\n",
    "survey_df_countryfix['Q4: COUNTRY'].replace({np.nan: 'US', '0': 'US'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    1537\n",
       "CA     129\n",
       "GB      15\n",
       "DE       5\n",
       "IE       3\n",
       "JP       3\n",
       "NL       3\n",
       "DK       2\n",
       "KR       2\n",
       "FR       2\n",
       "CH       2\n",
       "MX       2\n",
       "AU       1\n",
       "CN       1\n",
       "CR       1\n",
       "IS       1\n",
       "TW       1\n",
       "AE       1\n",
       "ES       1\n",
       "GR       1\n",
       "Name: Q4: COUNTRY, dtype: int64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_countryfix['Q4: COUNTRY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning State Fields <a class=\"anchor\" id=\"states\"></a>\n",
    "Our ol' faithful dictionary-based solution gets markedly less efficient here. Every country has numerous states, all with their own abbreviations, slang and ways for a wayward survey-doer to go awry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California       104\n",
       "CA                62\n",
       "Texas             43\n",
       "Illinois          42\n",
       "Oregon            38\n",
       "                ... \n",
       "Ri                 1\n",
       "indiana            1\n",
       "New Hampshire      1\n",
       "calif              1\n",
       "in                 1\n",
       "Name: Q5: STATE, PROVINCE, COUNTY, ETC, Length: 412, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_countryfix['Q5: STATE, PROVINCE, COUNTY, ETC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_statefix = survey_df_countryfix.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes each state upper case, strips them of punctuation and removes spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_statefix['Q5: STATE, PROVINCE, COUNTY, ETC'] = [str(country).upper() for country in survey_df_statefix['Q5: STATE, PROVINCE, COUNTY, ETC']]\n",
    "\n",
    "for ind, country in enumerate(survey_df_statefix['Q5: STATE, PROVINCE, COUNTY, ETC']):\n",
    "    survey_df_statefix.loc[ind, 'Q5: STATE, PROVINCE, COUNTY, ETC'] = ''.join([char.replace(' ', '') for char in survey_df_statefix.loc[ind, 'Q5: STATE, PROVINCE, COUNTY, ETC'] if char not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CALIFORNIA                          134\n",
       "CA                                   83\n",
       "ILLINOIS                             55\n",
       "TEXAS                                50\n",
       "ONTARIO                              47\n",
       "                                   ... \n",
       "OAKLANDCOUNTYMICHIGAN                 1\n",
       "OBLIVIONIFTHINGSKEEPGOINGTHISWAY      1\n",
       "TEHAMA                                1\n",
       "NEWFOUNDLANDANDLABRADOR               1\n",
       "RAPPAHANNOCKCOUNTYVA                  1\n",
       "Name: Q5: STATE, PROVINCE, COUNTY, ETC, Length: 258, dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_statefix['Q5: STATE, PROVINCE, COUNTY, ETC'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use pycountry's subdivision object to iterate through our states and make them consistent. The final output will be state names. Process:\n",
    "1. Create list of subdivision objects containing state codes and names.\n",
    "2. Extract state code, country code and state name, then put them into a dictionary. Altering subdivision list properties can have unintended consequences on all instances, even if you deep copy the list, which is why I'm going to the trouble of housing them in a different object.\n",
    "2. Create separate list of sanitised state names (i.e. all caps, no punctuation or spaces), then replace the ones in the dictionary with those.\n",
    "3. Loop through each state in the dataframe, replacing them with codes from the dictionary.\n",
    "4. Use codes to insert original subdivision state names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subdivision(code='AD-02', country_code='AD', name='Canillo', parent_code=None, type='Parish')"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pycountry as pc\n",
    "\n",
    "original_subdivs = list(pc.subdivisions)\n",
    "original_subdivs[0] # What a subdivision looks like. Various methods access each component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdiv_dict = dict()\n",
    "for ind, state in enumerate(original_subdivs):\n",
    "    subdiv_dict.update({original_subdivs[ind].code: [original_subdivs[ind].country.alpha_2, original_subdivs[ind].name]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AD-02', ['AD', 'Canillo']),\n",
       " ('AD-03', ['AD', 'Encamp']),\n",
       " ('AD-04', ['AD', 'La Massana']),\n",
       " ('AD-05', ['AD', 'Ordino']),\n",
       " ('AD-06', ['AD', 'Sant Julià de Lòria'])]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(subdiv_dict.items())[:5] # What the dictionary looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdiv_dict_caps = subdiv_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, values in subdiv_dict_caps.items():\n",
    "    subdiv_dict_caps.update({key: [values[0], ''.join([char.replace(' ', '').upper() for char in values[1] if char not in string.punctuation])]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AD-02', ['AD', 'CANILLO']),\n",
       " ('AD-03', ['AD', 'ENCAMP']),\n",
       " ('AD-04', ['AD', 'LAMASSANA']),\n",
       " ('AD-05', ['AD', 'ORDINO']),\n",
       " ('AD-06', ['AD', 'SANTJULIÀDELÒRIA'])]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(subdiv_dict_caps.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes 2 - 3 minutes to run.\n",
    "for ind, state in enumerate(survey_df_statefix['Q5: STATE, PROVINCE, COUNTY, ETC']):\n",
    "    for key, values in subdiv_dict_caps.items():\n",
    "        if values[0] in survey_df_statefix.loc[ind, 'Q4: COUNTRY']:\n",
    "            if values[1] in survey_df_statefix.loc[ind, 'Q5: STATE, PROVINCE, COUNTY, ETC']:\n",
    "                survey_df_statefix.loc[ind, 'Q5: STATE, PROVINCE, COUNTY, ETC'] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.74% of states were not captured.\n"
     ]
    }
   ],
   "source": [
    "failrate = round((len([dudstate for dudstate in survey_df_statefix['Q5: STATE, PROVINCE, COUNTY, ETC'] if len(dudstate) > 6])/len(survey_df_statefix['Q5: STATE, PROVINCE, COUNTY, ETC'])) * 100, 2)\n",
    "\n",
    "print(f'{failrate}% of states were not captured.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US-CA                   148\n",
       "CA                       83\n",
       "US-IL                    56\n",
       "US-WA                    52\n",
       "US-TX                    51\n",
       "                       ... \n",
       "SANJOSE                   1\n",
       "MT                        1\n",
       "WASPOKANE                 1\n",
       "SOUTHHOLLAND              1\n",
       "RAPPAHANNOCKCOUNTYVA      1\n",
       "Name: Q5: STATE, PROVINCE, COUNTY, ETC, Length: 209, dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_statefix['Q5: STATE, PROVINCE, COUNTY, ETC'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like a few states didn't quite convert to the country-state code pairings we need, CA being a big one. We can search for these rogue codes within our dictionary keys (country-state pairings) to capture the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes 2 - 3 minutes to run.\n",
    "for ind, state in enumerate(survey_df_statefix['Q5: STATE, PROVINCE, COUNTY, ETC']):\n",
    "    for key, values in subdiv_dict.items():\n",
    "        if values[0] in survey_df_statefix.loc[ind, 'Q4: COUNTRY']:\n",
    "            if survey_df_statefix.loc[ind, 'Q5: STATE, PROVINCE, COUNTY, ETC'] in key:\n",
    "                survey_df_statefix.loc[ind, 'Q5: STATE, PROVINCE, COUNTY, ETC'] = values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California              231\n",
       "Washington               95\n",
       "New York                 81\n",
       "Illinois                 76\n",
       "Texas                    69\n",
       "                       ... \n",
       "Midlothian                1\n",
       "KENT                      1\n",
       "ORANGECOUNTYCA            1\n",
       "Devon                     1\n",
       "RAPPAHANNOCKCOUNTYVA      1\n",
       "Name: Q5: STATE, PROVINCE, COUNTY, ETC, Length: 166, dtype: int64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 30\n",
    "survey_df_statefix['Q5: STATE, PROVINCE, COUNTY, ETC'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now impute all unrecognised values as 'Unknown', then promptly slap whoever set up the survey for making all this necessary.\n",
    "\n",
    "Note: While these unrecognised values are a combination of nulls and joke answers, we are losing a portion of legitimate responses. Capturing the few loose strands of legitimacy would unfortunately be a huge timesink, and there aren't enough to warrant a complex separate solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 nulls\n",
      "86 uncaptured values\n"
     ]
    }
   ],
   "source": [
    "null_values = len([state for state in survey_df_statefix['Q5: STATE, PROVINCE, COUNTY, ETC'] if state == '0'])\n",
    "uncaptured_values = len([state for state in survey_df_statefix['Q5: STATE, PROVINCE, COUNTY, ETC'] if state.isupper() == True])\n",
    "\n",
    "print(f'{null_values} nulls\\n{uncaptured_values} uncaptured values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, state in enumerate(survey_df_statefix['Q5: STATE, PROVINCE, COUNTY, ETC']):\n",
    "    if state.isupper() == True or state == '0':\n",
    "        survey_df_statefix.loc[ind, 'Q5: STATE, PROVINCE, COUNTY, ETC'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 nulls\n",
      "0 uncaptured values\n"
     ]
    }
   ],
   "source": [
    "null_values = len([state for state in survey_df_statefix['Q5: STATE, PROVINCE, COUNTY, ETC'] if state == '0'])\n",
    "uncaptured_values = len([state for state in survey_df_statefix['Q5: STATE, PROVINCE, COUNTY, ETC'] if state.isupper() == True])\n",
    "\n",
    "print(f'{null_values} nulls\\n{uncaptured_values} uncaptured values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpivoting Q6 <a class=\"anchor\" id=\"unpivot\"></a>\n",
    "Perhaps the worst eyesore in the whole dataset is how question six gingerly manspreads across 100+ columns.\n",
    "\n",
    "Our final major task will be to unpivot, or 'melt', these columns so they run vertically rather than horziontally. This will make the data easier to query later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internal ID</th>\n",
       "      <th>Q1: GOING OUT?</th>\n",
       "      <th>Q2: GENDER</th>\n",
       "      <th>Q3: AGE</th>\n",
       "      <th>Q4: COUNTRY</th>\n",
       "      <th>Q5: STATE, PROVINCE, COUNTY, ETC</th>\n",
       "      <th>Q6 | 100 Grand Bar</th>\n",
       "      <th>Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)</th>\n",
       "      <th>Q6 | Any full-sized candy bar</th>\n",
       "      <th>Q6 | Black Jacks</th>\n",
       "      <th>...</th>\n",
       "      <th>Q6 | Tolberone something or other</th>\n",
       "      <th>Q6 | Trail Mix</th>\n",
       "      <th>Q6 | Twix</th>\n",
       "      <th>Q6 | Vials of pure high fructose corn syrup, for main-lining into your vein</th>\n",
       "      <th>Q6 | Vicodin</th>\n",
       "      <th>Q6 | Whatchamacallit Bars</th>\n",
       "      <th>Q6 | White Bread</th>\n",
       "      <th>Q6 | Whole Wheat anything</th>\n",
       "      <th>Q6 | York Peppermint Patties</th>\n",
       "      <th>Q12: MEDIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90272821</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>US</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90272840</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>US</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90272841</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>US</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Internal ID Q1: GOING OUT? Q2: GENDER  Q3: AGE Q4: COUNTRY  \\\n",
       "0     90272821             No       Male       44          US   \n",
       "1     90272840             No       Male       40          US   \n",
       "2     90272841             No       Male       23          US   \n",
       "\n",
       "  Q5: STATE, PROVINCE, COUNTY, ETC  Q6 | 100 Grand Bar  \\\n",
       "0                       New Mexico                   2   \n",
       "1                           Oregon                   2   \n",
       "2                          Unknown                   3   \n",
       "\n",
       "   Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)  \\\n",
       "0                                                  1                                        \n",
       "1                                                  1                                        \n",
       "2                                                  1                                        \n",
       "\n",
       "   Q6 | Any full-sized candy bar  Q6 | Black Jacks  ...  \\\n",
       "0                              3                 2  ...   \n",
       "1                              3                 2  ...   \n",
       "2                              3                 1  ...   \n",
       "\n",
       "   Q6 | Tolberone something or other  Q6 | Trail Mix  Q6 | Twix  \\\n",
       "0                                  3               1          3   \n",
       "1                                  3               2          3   \n",
       "2                                  3               1          3   \n",
       "\n",
       "   Q6 | Vials of pure high fructose corn syrup, for main-lining into your vein  \\\n",
       "0                                                  1                             \n",
       "1                                                  1                             \n",
       "2                                                  2                             \n",
       "\n",
       "   Q6 | Vicodin  Q6 | Whatchamacallit Bars  Q6 | White Bread  \\\n",
       "0             1                          1                 1   \n",
       "1             3                          3                 1   \n",
       "2             3                          3                 1   \n",
       "\n",
       "   Q6 | Whole Wheat anything  Q6 | York Peppermint Patties  Q12: MEDIA  \n",
       "0                          1                             1     Science  \n",
       "1                          1                             1     Science  \n",
       "2                          1                             3     Science  \n",
       "\n",
       "[3 rows x 110 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_statefix.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we first need to bring the media column up..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_col = survey_df_statefix.pop('Q12: MEDIA')\n",
    "survey_df_statefix.insert(6, 'Q12: MEDIA', media_col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...then remove the 'Q6' part of each lolly preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, row in enumerate(survey_df_statefix.loc[:, 'Q6 | 100 Grand Bar':]):\n",
    "    survey_df_statefix.columns = [row.replace('Q6 | ', '') for row in survey_df_statefix.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for the magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_unpivoted = survey_df_statefix.melt(id_vars=['Internal ID', 'Q1: GOING OUT?',\t'Q2: GENDER', 'Q3: AGE', 'Q4: COUNTRY',\t'Q5: STATE, PROVINCE, COUNTY, ETC', 'Q12: MEDIA'], var_name='Topic', value_name='Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internal ID</th>\n",
       "      <th>Q1: GOING OUT?</th>\n",
       "      <th>Q2: GENDER</th>\n",
       "      <th>Q3: AGE</th>\n",
       "      <th>Q4: COUNTRY</th>\n",
       "      <th>Q5: STATE, PROVINCE, COUNTY, ETC</th>\n",
       "      <th>Q12: MEDIA</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90272821</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>US</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Science</td>\n",
       "      <td>100 Grand Bar</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90272840</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>US</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Science</td>\n",
       "      <td>100 Grand Bar</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90272841</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>US</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Science</td>\n",
       "      <td>100 Grand Bar</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90272852</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>US</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Science</td>\n",
       "      <td>100 Grand Bar</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90272854</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>CA</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Science</td>\n",
       "      <td>100 Grand Bar</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176434</th>\n",
       "      <td>90314022</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>US</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Science</td>\n",
       "      <td>York Peppermint Patties</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176435</th>\n",
       "      <td>90314359</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>US</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>None</td>\n",
       "      <td>York Peppermint Patties</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176436</th>\n",
       "      <td>90314580</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>US</td>\n",
       "      <td>New York</td>\n",
       "      <td>Science</td>\n",
       "      <td>York Peppermint Patties</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176437</th>\n",
       "      <td>90314634</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>US</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Science</td>\n",
       "      <td>York Peppermint Patties</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176438</th>\n",
       "      <td>90314802</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>66</td>\n",
       "      <td>US</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Daily Dish</td>\n",
       "      <td>York Peppermint Patties</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176439 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Internal ID Q1: GOING OUT? Q2: GENDER  Q3: AGE Q4: COUNTRY  \\\n",
       "0          90272821             No       Male       44          US   \n",
       "1          90272840             No       Male       40          US   \n",
       "2          90272841             No       Male       23          US   \n",
       "3          90272852             No       Male       41          US   \n",
       "4          90272854             No       Male       33          CA   \n",
       "...             ...            ...        ...      ...         ...   \n",
       "176434     90314022             No     Female       26          US   \n",
       "176435     90314359             No       Male       24          US   \n",
       "176436     90314580             No     Female       33          US   \n",
       "176437     90314634             No     Female       26          US   \n",
       "176438     90314802             No     Female       66          US   \n",
       "\n",
       "       Q5: STATE, PROVINCE, COUNTY, ETC  Q12: MEDIA                    Topic  \\\n",
       "0                            New Mexico     Science            100 Grand Bar   \n",
       "1                                Oregon     Science            100 Grand Bar   \n",
       "2                               Unknown     Science            100 Grand Bar   \n",
       "3                               Unknown     Science            100 Grand Bar   \n",
       "4                               Ontario     Science            100 Grand Bar   \n",
       "...                                 ...         ...                      ...   \n",
       "176434                         Michigan     Science  York Peppermint Patties   \n",
       "176435                         Maryland        None  York Peppermint Patties   \n",
       "176436                         New York     Science  York Peppermint Patties   \n",
       "176437                        Tennessee     Science  York Peppermint Patties   \n",
       "176438                     Pennsylvania  Daily Dish  York Peppermint Patties   \n",
       "\n",
       "        Rating  \n",
       "0            2  \n",
       "1            2  \n",
       "2            3  \n",
       "3            3  \n",
       "4            3  \n",
       "...        ...  \n",
       "176434       3  \n",
       "176435       2  \n",
       "176436       3  \n",
       "176437       2  \n",
       "176438       3  \n",
       "\n",
       "[176439 rows x 9 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_unpivoted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Up & Saving the Data <a class=\"anchor\" id=\"cleanup\"></a>\n",
    "\n",
    "Now it's time to correct any errant datatypes, rename the columns and save the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Internal ID                          int64\n",
       "Q1: GOING OUT?                      object\n",
       "Q2: GENDER                          object\n",
       "Q3: AGE                              int64\n",
       "Q4: COUNTRY                         object\n",
       "Q5: STATE, PROVINCE, COUNTY, ETC    object\n",
       "Q12: MEDIA                          object\n",
       "Topic                               object\n",
       "Rating                               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_unpivoted.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_unpivoted.rename(mapper={'Q1: GOING OUT?': 'Halloween Plans?', 'Q2: GENDER': 'Gender', 'Q3: AGE': 'Age', 'Q4: COUNTRY': 'Country',\n",
    "       'Q5: STATE, PROVINCE, COUNTY, ETC':'State', 'Q12: MEDIA':'Media Preference'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internal ID</th>\n",
       "      <th>Halloween Plans?</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Media Preference</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90272821</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>US</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Science</td>\n",
       "      <td>100 Grand Bar</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90272840</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>US</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Science</td>\n",
       "      <td>100 Grand Bar</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90272841</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>US</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Science</td>\n",
       "      <td>100 Grand Bar</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90272852</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>US</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Science</td>\n",
       "      <td>100 Grand Bar</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90272854</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>CA</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Science</td>\n",
       "      <td>100 Grand Bar</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176434</th>\n",
       "      <td>90314022</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>US</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Science</td>\n",
       "      <td>York Peppermint Patties</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176435</th>\n",
       "      <td>90314359</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>US</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>None</td>\n",
       "      <td>York Peppermint Patties</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176436</th>\n",
       "      <td>90314580</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>US</td>\n",
       "      <td>New York</td>\n",
       "      <td>Science</td>\n",
       "      <td>York Peppermint Patties</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176437</th>\n",
       "      <td>90314634</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>US</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Science</td>\n",
       "      <td>York Peppermint Patties</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176438</th>\n",
       "      <td>90314802</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>66</td>\n",
       "      <td>US</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Daily Dish</td>\n",
       "      <td>York Peppermint Patties</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176439 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Internal ID Halloween Plans?  Gender  Age Country         State  \\\n",
       "0          90272821               No    Male   44      US    New Mexico   \n",
       "1          90272840               No    Male   40      US        Oregon   \n",
       "2          90272841               No    Male   23      US       Unknown   \n",
       "3          90272852               No    Male   41      US       Unknown   \n",
       "4          90272854               No    Male   33      CA       Ontario   \n",
       "...             ...              ...     ...  ...     ...           ...   \n",
       "176434     90314022               No  Female   26      US      Michigan   \n",
       "176435     90314359               No    Male   24      US      Maryland   \n",
       "176436     90314580               No  Female   33      US      New York   \n",
       "176437     90314634               No  Female   26      US     Tennessee   \n",
       "176438     90314802               No  Female   66      US  Pennsylvania   \n",
       "\n",
       "       Media Preference                    Topic  Rating  \n",
       "0               Science            100 Grand Bar       2  \n",
       "1               Science            100 Grand Bar       2  \n",
       "2               Science            100 Grand Bar       3  \n",
       "3               Science            100 Grand Bar       3  \n",
       "4               Science            100 Grand Bar       3  \n",
       "...                 ...                      ...     ...  \n",
       "176434          Science  York Peppermint Patties       3  \n",
       "176435             None  York Peppermint Patties       2  \n",
       "176436          Science  York Peppermint Patties       3  \n",
       "176437          Science  York Peppermint Patties       2  \n",
       "176438       Daily Dish  York Peppermint Patties       3  \n",
       "\n",
       "[176439 rows x 9 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_unpivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_unpivoted.to_excel(pwd + '\\data3_clean_survey_output.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just like that, the dataset from hell isn't looking so spooky anymore! Thanks for following along. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dde02ba5f02bed1806cc8e85d7502b2a49e870f028b658100d04c0f04704b452"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

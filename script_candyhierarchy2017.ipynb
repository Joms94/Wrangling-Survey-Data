{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling University of British Columbia Survey Data\n",
    "In this notebook, I accomplish the following:\n",
    "* Get an overview of the data.\n",
    "* Check the Internal ID column for duplicates.\n",
    "* Clean age values.\n",
    "* Drop unnecessary columns.\n",
    "* Combine the four media columns.\n",
    "* Delete abandoned responses.\n",
    "* Fill invalid categorical fields.\n",
    "* Convert each of the three categories of opinion on each lolly to an integer.\n",
    "* Standardise the country and state fields.\n",
    "* 'Unpivot' the data, moving lolly preference columns to rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Personal\\Education\\Programming\\Anaconda1\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "pwd = os.getcwd() # Helps with file management.\n",
    "survey_df = pd.read_excel(pwd + '\\data_candyhierarchy2017.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internal ID</th>\n",
       "      <th>Q1: GOING OUT?</th>\n",
       "      <th>Q2: GENDER</th>\n",
       "      <th>Q3: AGE</th>\n",
       "      <th>Q4: COUNTRY</th>\n",
       "      <th>Q5: STATE, PROVINCE, COUNTY, ETC</th>\n",
       "      <th>Q6 | 100 Grand Bar</th>\n",
       "      <th>Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)</th>\n",
       "      <th>Q6 | Any full-sized candy bar</th>\n",
       "      <th>Q6 | Black Jacks</th>\n",
       "      <th>...</th>\n",
       "      <th>Q8: DESPAIR OTHER</th>\n",
       "      <th>Q9: OTHER COMMENTS</th>\n",
       "      <th>Q10: DRESS</th>\n",
       "      <th>Unnamed: 113</th>\n",
       "      <th>Q11: DAY</th>\n",
       "      <th>Q12: MEDIA [Daily Dish]</th>\n",
       "      <th>Q12: MEDIA [Science]</th>\n",
       "      <th>Q12: MEDIA [ESPN]</th>\n",
       "      <th>Q12: MEDIA [Yahoo]</th>\n",
       "      <th>Click Coordinates (x, y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90258773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90272821</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>USA</td>\n",
       "      <td>NM</td>\n",
       "      <td>MEH</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bottom line is Twix is really the only candy w...</td>\n",
       "      <td>White and gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(84, 25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90272829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>49</td>\n",
       "      <td>USA</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90272840</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>us</td>\n",
       "      <td>or</td>\n",
       "      <td>MEH</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Raisins can go to hell</td>\n",
       "      <td>White and gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(75, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90272841</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>usa</td>\n",
       "      <td>exton pa</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White and gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(70, 10)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Internal ID Q1: GOING OUT? Q2: GENDER Q3: AGE Q4: COUNTRY  \\\n",
       "0     90258773            NaN        NaN     NaN         NaN   \n",
       "1     90272821             No       Male      44        USA    \n",
       "2     90272829            NaN       Male      49         USA   \n",
       "3     90272840             No       Male      40          us   \n",
       "4     90272841             No       Male      23         usa   \n",
       "\n",
       "  Q5: STATE, PROVINCE, COUNTY, ETC Q6 | 100 Grand Bar  \\\n",
       "0                              NaN                NaN   \n",
       "1                               NM                MEH   \n",
       "2                         Virginia                NaN   \n",
       "3                               or                MEH   \n",
       "4                         exton pa                JOY   \n",
       "\n",
       "  Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)  \\\n",
       "0                                                NaN                                       \n",
       "1                                            DESPAIR                                       \n",
       "2                                                NaN                                       \n",
       "3                                            DESPAIR                                       \n",
       "4                                            DESPAIR                                       \n",
       "\n",
       "  Q6 | Any full-sized candy bar Q6 | Black Jacks  ... Q8: DESPAIR OTHER  \\\n",
       "0                           NaN              NaN  ...               NaN   \n",
       "1                           JOY              MEH  ...               NaN   \n",
       "2                           NaN              NaN  ...               NaN   \n",
       "3                           JOY              MEH  ...               NaN   \n",
       "4                           JOY          DESPAIR  ...               NaN   \n",
       "\n",
       "                                  Q9: OTHER COMMENTS      Q10: DRESS  \\\n",
       "0                                                NaN             NaN   \n",
       "1  Bottom line is Twix is really the only candy w...  White and gold   \n",
       "2                                                NaN             NaN   \n",
       "3                             Raisins can go to hell  White and gold   \n",
       "4                                                NaN  White and gold   \n",
       "\n",
       "  Unnamed: 113 Q11: DAY Q12: MEDIA [Daily Dish] Q12: MEDIA [Science]  \\\n",
       "0          NaN      NaN                     NaN                  NaN   \n",
       "1          NaN   Sunday                     NaN                  1.0   \n",
       "2          NaN      NaN                     NaN                  NaN   \n",
       "3          NaN   Sunday                     NaN                  1.0   \n",
       "4          NaN   Friday                     NaN                  1.0   \n",
       "\n",
       "  Q12: MEDIA [ESPN] Q12: MEDIA [Yahoo] Click Coordinates (x, y)  \n",
       "0               NaN                NaN                      NaN  \n",
       "1               NaN                NaN                 (84, 25)  \n",
       "2               NaN                NaN                      NaN  \n",
       "3               NaN                NaN                 (75, 23)  \n",
       "4               NaN                NaN                 (70, 10)  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internal ID</th>\n",
       "      <th>Q12: MEDIA [Daily Dish]</th>\n",
       "      <th>Q12: MEDIA [Science]</th>\n",
       "      <th>Q12: MEDIA [ESPN]</th>\n",
       "      <th>Q12: MEDIA [Yahoo]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.460000e+03</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1362.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.028016e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.435532e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.025877e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.027520e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.027780e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.028242e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.031480e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Internal ID  Q12: MEDIA [Daily Dish]  Q12: MEDIA [Science]  \\\n",
       "count  2.460000e+03                     85.0                1362.0   \n",
       "mean   9.028016e+07                      1.0                   1.0   \n",
       "std    7.435532e+03                      0.0                   0.0   \n",
       "min    9.025877e+07                      1.0                   1.0   \n",
       "25%    9.027520e+07                      1.0                   1.0   \n",
       "50%    9.027780e+07                      1.0                   1.0   \n",
       "75%    9.028242e+07                      1.0                   1.0   \n",
       "max    9.031480e+07                      1.0                   1.0   \n",
       "\n",
       "       Q12: MEDIA [ESPN]  Q12: MEDIA [Yahoo]  \n",
       "count               99.0                67.0  \n",
       "mean                 1.0                 1.0  \n",
       "std                  0.0                 0.0  \n",
       "min                  1.0                 1.0  \n",
       "25%                  1.0                 1.0  \n",
       "50%                  1.0                 1.0  \n",
       "75%                  1.0                 1.0  \n",
       "max                  1.0                 1.0  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'll be worth describing the data again once we've converted survey responses to numeric values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Duplicate Respondents\n",
    "Never trust an assumption about your data until you've verified it, especially when it's this zany!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total IDs: 2460\n",
      "Unique IDs: 2460\n"
     ]
    }
   ],
   "source": [
    "print(f'Total IDs: {len(survey_df[\"Internal ID\"])}')\n",
    "print(f'Unique IDs: {survey_df[\"Internal ID\"].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Age Values\n",
    "The data contain a few... aberrant responses.\n",
    "\n",
    "Note: I'll be making a few copies throughout so it's easier to track my progress at different stages and roll back mistakes. \n",
    "The tradeoff is storing a bunch of variables, but for a project of this size it's not a real concern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_agedrop = survey_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values: 84\n",
      "Non-numeric values: 24\n",
      "Total values: 2460\n"
     ]
    }
   ],
   "source": [
    "print(f'Null values: {survey_df_agedrop[\"Q3: AGE\"].isna().sum()}')\n",
    "print(f'Non-numeric values: {len([age for age in survey_df_agedrop[\"Q3: AGE\"] if isinstance(age, str) == True])}')\n",
    "print(f'Total values: {len(survey_df_agedrop[\"Q3: AGE\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We therefore need 108 cells to be 0 whilst preserving the int64 dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0       108\n",
       "40.0       92\n",
       "34.0       90\n",
       "37.0       89\n",
       "43.0       86\n",
       "36.0       79\n",
       "42.0       79\n",
       "35.0       77\n",
       "38.0       76\n",
       "44.0       76\n",
       "33.0       75\n",
       "45.0       75\n",
       "41.0       74\n",
       "50.0       71\n",
       "39.0       69\n",
       "49.0       69\n",
       "32.0       68\n",
       "48.0       64\n",
       "47.0       63\n",
       "30.0       62\n",
       "53.0       57\n",
       "46.0       55\n",
       "52.0       50\n",
       "56.0       46\n",
       "27.0       45\n",
       "31.0       45\n",
       "51.0       41\n",
       "28.0       37\n",
       "54.0       36\n",
       "58.0       34\n",
       "55.0       32\n",
       "60.0       31\n",
       "29.0       27\n",
       "57.0       25\n",
       "59.0       24\n",
       "26.0       23\n",
       "63.0       20\n",
       "62.0       20\n",
       "61.0       20\n",
       "25.0       19\n",
       "64.0       17\n",
       "24.0       16\n",
       "21.0       14\n",
       "65.0       13\n",
       "20.0       12\n",
       "22.0       11\n",
       "18.0       10\n",
       "23.0        9\n",
       "66.0        9\n",
       "12.0        9\n",
       "15.0        8\n",
       "70.0        8\n",
       "68.0        8\n",
       "11.0        7\n",
       "13.0        6\n",
       "71.0        6\n",
       "72.0        6\n",
       "67.0        6\n",
       "17.0        5\n",
       "69.0        5\n",
       "9.0         4\n",
       "16.0        4\n",
       "73.0        4\n",
       "75.0        3\n",
       "19.0        3\n",
       "10.0        3\n",
       "8.0         2\n",
       "90.0        2\n",
       "76.0        2\n",
       "6.0         2\n",
       "14.0        2\n",
       "7.0         2\n",
       "100.0       2\n",
       "74.0        1\n",
       "77.0        1\n",
       "4.0         1\n",
       "1.0         1\n",
       "102.0       1\n",
       "39.4        1\n",
       "88.0        1\n",
       "312.0       1\n",
       "70.5        1\n",
       "99.0        1\n",
       "1000.0      1\n",
       "Name: Q3: AGE, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_agedrop['Q3: AGE'] = pd.to_numeric(survey_df_agedrop['Q3: AGE'], errors='coerce')\n",
    "survey_df_agedrop.replace(np.nan, 0, inplace=True)\n",
    "survey_df_agedrop.astype({'Q3: AGE': 'int64'}, errors='ignore', copy=False)\n",
    "survey_df_agedrop['Q3: AGE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values: 0\n",
      "Non-numeric values: 0\n",
      "2460\n"
     ]
    }
   ],
   "source": [
    "print(f'Null values: {survey_df_agedrop[\"Q3: AGE\"].isna().sum()}')\n",
    "print(f'Non-numeric values: {len([age for age in survey_df_agedrop[\"Q3: AGE\"] if isinstance(age, str) == True])}')\n",
    "print(len(survey_df_agedrop['Q3: AGE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all the rubbish has been swept out, time for a sense-check. It's very unlikely that a 300-year-old is taking this survey. I'm going to assume anyone aged 90 or over is just trying to be funny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dubious ages: 8\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of dubious ages: {len([age for age in survey_df_agedrop[\"Q3: AGE\"] if age >= 90])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_sensecheck = survey_df_agedrop.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dubious ages: 0\n"
     ]
    }
   ],
   "source": [
    "survey_df_sensecheck[\"Q3: AGE\"] = [int(age) if age < 90 else 0 for age in survey_df_sensecheck[\"Q3: AGE\"]]\n",
    "print(f'Number of dubious ages: {len([age for age in survey_df_sensecheck[\"Q3: AGE\"] if age >= 90])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd also like to exclude a few exceptionally young ages. Halloween lollies are the domain of kids, but I'd say it's highly unlikely any kid under three is capable of coherent opinions. If you were an opinionated two-year-old, don't hesitate to refrain from letting me know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of far-too-young ages: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of far-too-young ages: {len([age for age in survey_df_sensecheck[\"Q3: AGE\"] if age <= 2 and age != 0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of far-too-young ages: 0\n"
     ]
    }
   ],
   "source": [
    "survey_df_sensecheck[\"Q3: AGE\"] = [int(age) if age > 2 else 0 for age in survey_df_sensecheck[\"Q3: AGE\"]]\n",
    "print(f'Number of far-too-young ages: {len([age for age in survey_df_sensecheck[\"Q3: AGE\"] if age <= 2 and age != 0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish up, I'm going to replace all 0s with the median age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41    191\n",
       "40     92\n",
       "34     90\n",
       "37     89\n",
       "43     86\n",
       "36     79\n",
       "42     79\n",
       "35     77\n",
       "44     76\n",
       "38     76\n",
       "33     75\n",
       "45     75\n",
       "50     71\n",
       "39     70\n",
       "49     69\n",
       "32     68\n",
       "48     64\n",
       "47     63\n",
       "30     62\n",
       "53     57\n",
       "46     55\n",
       "52     50\n",
       "56     46\n",
       "27     45\n",
       "31     45\n",
       "51     41\n",
       "28     37\n",
       "54     36\n",
       "58     34\n",
       "55     32\n",
       "60     31\n",
       "29     27\n",
       "57     25\n",
       "59     24\n",
       "26     23\n",
       "62     20\n",
       "63     20\n",
       "61     20\n",
       "25     19\n",
       "64     17\n",
       "24     16\n",
       "21     14\n",
       "65     13\n",
       "20     12\n",
       "22     11\n",
       "18     10\n",
       "66      9\n",
       "23      9\n",
       "70      9\n",
       "12      9\n",
       "15      8\n",
       "68      8\n",
       "11      7\n",
       "13      6\n",
       "72      6\n",
       "67      6\n",
       "71      6\n",
       "17      5\n",
       "69      5\n",
       "9       4\n",
       "73      4\n",
       "16      4\n",
       "75      3\n",
       "19      3\n",
       "10      3\n",
       "7       2\n",
       "6       2\n",
       "76      2\n",
       "14      2\n",
       "8       2\n",
       "4       1\n",
       "88      1\n",
       "74      1\n",
       "77      1\n",
       "Name: Q3: AGE, dtype: int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_sensecheck[\"Q3: AGE\"] = [age if age > 0 else survey_df_sensecheck[\"Q3: AGE\"].median() for age in survey_df_sensecheck[\"Q3: AGE\"]]\n",
    "survey_df_sensecheck[\"Q3: AGE\"] = survey_df_sensecheck[\"Q3: AGE\"].astype('int64')\n",
    "survey_df_sensecheck[\"Q3: AGE\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Unneeded Columns\n",
    "There are several suspect columns in this dataset that are unlikely to be valuable without the aid of quantum computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Internal ID', 'Q1: GOING OUT?', 'Q2: GENDER', 'Q3: AGE', 'Q4: COUNTRY',\n",
       "       'Q5: STATE, PROVINCE, COUNTY, ETC', 'Q6 | 100 Grand Bar',\n",
       "       'Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)',\n",
       "       'Q6 | Any full-sized candy bar', 'Q6 | Black Jacks',\n",
       "       ...\n",
       "       'Q8: DESPAIR OTHER', 'Q9: OTHER COMMENTS', 'Q10: DRESS', 'Unnamed: 113',\n",
       "       'Q11: DAY', 'Q12: MEDIA [Daily Dish]', 'Q12: MEDIA [Science]',\n",
       "       'Q12: MEDIA [ESPN]', 'Q12: MEDIA [Yahoo]', 'Click Coordinates (x, y)'],\n",
       "      dtype='object', length=120)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_sensecheck.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                          2451\n",
       "dress (https://survey.ubc.ca/media/assets/user/14372/storage/dress.png)       9\n",
       "Name: Unnamed: 113, dtype: int64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_sensecheck['Unnamed: 113'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Internal ID', 'Q1: GOING OUT?', 'Q2: GENDER', 'Q3: AGE', 'Q4: COUNTRY',\n",
       "       'Q5: STATE, PROVINCE, COUNTY, ETC', 'Q6 | 100 Grand Bar',\n",
       "       'Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)',\n",
       "       'Q6 | Any full-sized candy bar', 'Q6 | Black Jacks',\n",
       "       ...\n",
       "       'Q6 | Whatchamacallit Bars', 'Q6 | White Bread',\n",
       "       'Q6 | Whole Wheat anything', 'Q6 | York Peppermint Patties', 'Q11: DAY',\n",
       "       'Q12: MEDIA [Daily Dish]', 'Q12: MEDIA [Science]', 'Q12: MEDIA [ESPN]',\n",
       "       'Q12: MEDIA [Yahoo]', 'Click Coordinates (x, y)'],\n",
       "      dtype='object', length=115)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_coldrops = survey_df_sensecheck.copy()\n",
    "survey_df_coldrops.drop(columns=['Q7: JOY OTHER', 'Q8: DESPAIR OTHER', 'Q9: OTHER COMMENTS', 'Unnamed: 113', 'Q10: DRESS'], inplace=True)\n",
    "survey_df_coldrops.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Media Columns\n",
    "The media columns are a highly-unrelated portion of the survey where respondents are presented with four mobile homepages and asked to honestly select which one they'd click on. \n",
    "\n",
    "I want a single media column containing a categorical variable for each of the media organisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_media = survey_df_coldrops.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm thinking I handle this via the following process:\n",
    "1. Change media column values to 1 - 4, where 2 would be 'Science', 3 would be 'ESPN' etc.\n",
    "2. Collapse all values into new MEDIA column.\n",
    "3. Convert values 1 - 4 into 'Daily Dish' - 'Yahoo' respectively.\n",
    "4. Drop all four original media columns.\n",
    "\n",
    "If any of these clowns have selected multiple answers, we'll know soon enough!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_changer(data, numadd):\n",
    "    result = [i + numadd if i > 0 else i for i in data]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_data = ['Q12: MEDIA [Daily Dish]', 'Q12: MEDIA [Science]', 'Q12: MEDIA [ESPN]', 'Q12: MEDIA [Yahoo]']\n",
    "\n",
    "for ind, media_col in enumerate(media_data):\n",
    "    survey_df_media[media_col] = num_changer(survey_df_media[media_col], ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q12: MEDIA [Daily Dish]</th>\n",
       "      <th>Q12: MEDIA [Science]</th>\n",
       "      <th>Q12: MEDIA [ESPN]</th>\n",
       "      <th>Q12: MEDIA [Yahoo]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q12: MEDIA [Daily Dish]  Q12: MEDIA [Science]  Q12: MEDIA [ESPN]  \\\n",
       "1770                      0.0                   0.0                0.0   \n",
       "1771                      0.0                   0.0                0.0   \n",
       "1772                      0.0                   0.0                0.0   \n",
       "1773                      0.0                   2.0                0.0   \n",
       "1774                      0.0                   2.0                0.0   \n",
       "1775                      0.0                   0.0                0.0   \n",
       "1776                      0.0                   2.0                0.0   \n",
       "1777                      0.0                   0.0                0.0   \n",
       "1778                      0.0                   2.0                0.0   \n",
       "1779                      0.0                   2.0                0.0   \n",
       "1780                      0.0                   0.0                0.0   \n",
       "1781                      0.0                   0.0                0.0   \n",
       "1782                      0.0                   0.0                0.0   \n",
       "1783                      0.0                   2.0                0.0   \n",
       "1784                      1.0                   0.0                0.0   \n",
       "1785                      0.0                   0.0                0.0   \n",
       "1786                      0.0                   2.0                0.0   \n",
       "1787                      0.0                   0.0                3.0   \n",
       "1788                      0.0                   0.0                0.0   \n",
       "1789                      0.0                   0.0                0.0   \n",
       "1790                      0.0                   2.0                0.0   \n",
       "\n",
       "      Q12: MEDIA [Yahoo]  \n",
       "1770                 0.0  \n",
       "1771                 0.0  \n",
       "1772                 4.0  \n",
       "1773                 0.0  \n",
       "1774                 0.0  \n",
       "1775                 0.0  \n",
       "1776                 0.0  \n",
       "1777                 0.0  \n",
       "1778                 0.0  \n",
       "1779                 0.0  \n",
       "1780                 0.0  \n",
       "1781                 0.0  \n",
       "1782                 0.0  \n",
       "1783                 0.0  \n",
       "1784                 0.0  \n",
       "1785                 0.0  \n",
       "1786                 0.0  \n",
       "1787                 0.0  \n",
       "1788                 0.0  \n",
       "1789                 0.0  \n",
       "1790                 0.0  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_media[media_data].loc[1770:1790] # I've taken this oddball slice because it contains responses in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1770    0.0\n",
       "1771    0.0\n",
       "1772    4.0\n",
       "1773    2.0\n",
       "1774    2.0\n",
       "1775    0.0\n",
       "1776    2.0\n",
       "1777    0.0\n",
       "1778    2.0\n",
       "1779    2.0\n",
       "1780    0.0\n",
       "1781    0.0\n",
       "1782    0.0\n",
       "1783    2.0\n",
       "1784    1.0\n",
       "1785    0.0\n",
       "1786    2.0\n",
       "1787    3.0\n",
       "1788    0.0\n",
       "1789    0.0\n",
       "1790    2.0\n",
       "Name: Q12: MEDIA, dtype: float64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_media['Q12: MEDIA'] = survey_df_media[media_data].sum(axis=1)\n",
    "survey_df_media['Q12: MEDIA'].loc[1770:1790]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Personal\\Education\\Programming\\Anaconda1\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1770          None\n",
       "1771          None\n",
       "1772         Yahoo\n",
       "1773       Science\n",
       "1774       Science\n",
       "1775          None\n",
       "1776       Science\n",
       "1777          None\n",
       "1778       Science\n",
       "1779       Science\n",
       "1780          None\n",
       "1781          None\n",
       "1782          None\n",
       "1783       Science\n",
       "1784    Daily Dish\n",
       "1785          None\n",
       "1786       Science\n",
       "1787          ESPN\n",
       "1788          None\n",
       "1789          None\n",
       "1790       Science\n",
       "Name: Q12: MEDIA, dtype: object"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valuedict = {0: 'None',\n",
    "             1: 'Daily Dish',\n",
    "             2: 'Science',\n",
    "             3: 'ESPN',\n",
    "             4: 'Yahoo'}\n",
    "\n",
    "for key, value in valuedict.items():\n",
    "    survey_df_media['Q12: MEDIA'].loc[survey_df_media['Q12: MEDIA'] == key] = value\n",
    "\n",
    "survey_df_media['Q12: MEDIA'].loc[1770:1790]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: I'm aware that I'm using .loc slices in an unintended fashion. It's just a convenient way of filtering data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_media.drop(columns=media_data, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Science       1362\n",
       "None           847\n",
       "ESPN            99\n",
       "Daily Dish      85\n",
       "Yahoo           67\n",
       "Name: Q12: MEDIA, dtype: int64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_media['Q12: MEDIA'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Abandoned Responses\n",
    "Some users opened the survey, but immediately closed the tab. We'll delete these responses by scanning each row for responses of '0' in all main question fields, getting the index of each, then dropping them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 6, 10, 18]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowdrops = (survey_df_media.iloc[:, 6:111:1] == 0) # Returns a dataframe of True/ False values, where True = 0.\n",
    "dropindex = rowdrops.index[rowdrops['Q6 | 100 Grand Bar']].tolist()\n",
    "dropindex[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_abandrops = survey_df_media.copy()\n",
    "survey_df_abandrops.drop(dropindex, inplace=True)\n",
    "survey_df_abandrops.reset_index(inplace=True)\n",
    "survey_df_abandrops.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internal ID</th>\n",
       "      <th>Q1: GOING OUT?</th>\n",
       "      <th>Q2: GENDER</th>\n",
       "      <th>Q3: AGE</th>\n",
       "      <th>Q4: COUNTRY</th>\n",
       "      <th>Q5: STATE, PROVINCE, COUNTY, ETC</th>\n",
       "      <th>Q6 | 100 Grand Bar</th>\n",
       "      <th>Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)</th>\n",
       "      <th>Q6 | Any full-sized candy bar</th>\n",
       "      <th>Q6 | Black Jacks</th>\n",
       "      <th>...</th>\n",
       "      <th>Q6 | Twix</th>\n",
       "      <th>Q6 | Vials of pure high fructose corn syrup, for main-lining into your vein</th>\n",
       "      <th>Q6 | Vicodin</th>\n",
       "      <th>Q6 | Whatchamacallit Bars</th>\n",
       "      <th>Q6 | White Bread</th>\n",
       "      <th>Q6 | Whole Wheat anything</th>\n",
       "      <th>Q6 | York Peppermint Patties</th>\n",
       "      <th>Q11: DAY</th>\n",
       "      <th>Click Coordinates (x, y)</th>\n",
       "      <th>Q12: MEDIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90272821</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>USA</td>\n",
       "      <td>NM</td>\n",
       "      <td>MEH</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>...</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(84, 25)</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90272840</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>us</td>\n",
       "      <td>or</td>\n",
       "      <td>MEH</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>...</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(75, 23)</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90272841</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>usa</td>\n",
       "      <td>exton pa</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>...</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>JOY</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>Friday</td>\n",
       "      <td>(70, 10)</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90272852</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>0</td>\n",
       "      <td>(75, 23)</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90272854</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>canada</td>\n",
       "      <td>ontario</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>...</td>\n",
       "      <td>JOY</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>Friday</td>\n",
       "      <td>(55, 5)</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Internal ID Q1: GOING OUT? Q2: GENDER  Q3: AGE Q4: COUNTRY  \\\n",
       "0     90272821             No       Male       44        USA    \n",
       "1     90272840             No       Male       40          us   \n",
       "2     90272841             No       Male       23         usa   \n",
       "3     90272852             No       Male       41           0   \n",
       "4     90272854             No       Male       33      canada   \n",
       "\n",
       "  Q5: STATE, PROVINCE, COUNTY, ETC Q6 | 100 Grand Bar  \\\n",
       "0                               NM                MEH   \n",
       "1                               or                MEH   \n",
       "2                         exton pa                JOY   \n",
       "3                                0                JOY   \n",
       "4                          ontario                JOY   \n",
       "\n",
       "  Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)  \\\n",
       "0                                            DESPAIR                                       \n",
       "1                                            DESPAIR                                       \n",
       "2                                            DESPAIR                                       \n",
       "3                                            DESPAIR                                       \n",
       "4                                            DESPAIR                                       \n",
       "\n",
       "  Q6 | Any full-sized candy bar Q6 | Black Jacks  ... Q6 | Twix  \\\n",
       "0                           JOY              MEH  ...       JOY   \n",
       "1                           JOY              MEH  ...       JOY   \n",
       "2                           JOY          DESPAIR  ...       JOY   \n",
       "3                           JOY                0  ...       JOY   \n",
       "4                           JOY          DESPAIR  ...       JOY   \n",
       "\n",
       "  Q6 | Vials of pure high fructose corn syrup, for main-lining into your vein  \\\n",
       "0                                            DESPAIR                            \n",
       "1                                            DESPAIR                            \n",
       "2                                                MEH                            \n",
       "3                                            DESPAIR                            \n",
       "4                                                JOY                            \n",
       "\n",
       "  Q6 | Vicodin Q6 | Whatchamacallit Bars Q6 | White Bread  \\\n",
       "0      DESPAIR                   DESPAIR          DESPAIR   \n",
       "1          JOY                       JOY          DESPAIR   \n",
       "2          JOY                       JOY          DESPAIR   \n",
       "3      DESPAIR                       JOY          DESPAIR   \n",
       "4          MEH                   DESPAIR          DESPAIR   \n",
       "\n",
       "  Q6 | Whole Wheat anything Q6 | York Peppermint Patties Q11: DAY  \\\n",
       "0                   DESPAIR                      DESPAIR   Sunday   \n",
       "1                   DESPAIR                      DESPAIR   Sunday   \n",
       "2                   DESPAIR                          JOY   Friday   \n",
       "3                   DESPAIR                          JOY        0   \n",
       "4                   DESPAIR                      DESPAIR   Friday   \n",
       "\n",
       "  Click Coordinates (x, y) Q12: MEDIA  \n",
       "0                 (84, 25)    Science  \n",
       "1                 (75, 23)    Science  \n",
       "2                 (70, 10)    Science  \n",
       "3                 (75, 23)    Science  \n",
       "4                  (55, 5)    Science  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_abandrops.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling Invalid Categorical Fields\n",
    "There are only two valid choices ('Yes' and 'No'). I'm going to assume any response of 0 means they'd rather not say. This makes it consistent with the gender field, but even that has a similar issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1: GOING OUT?  Q2: GENDER        \n",
       "No              Male                  860\n",
       "                Female                493\n",
       "Yes             Male                  137\n",
       "                Female                 82\n",
       "No              I'd rather not say     48\n",
       "0               Male                   44\n",
       "No              Other                  18\n",
       "0               Female                  8\n",
       "Yes             I'd rather not say      8\n",
       "0               0                       4\n",
       "                I'd rather not say      4\n",
       "No              0                       3\n",
       "Yes             Other                   3\n",
       "0               Other                   1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_abandrops[['Q1: GOING OUT?', 'Q2: GENDER']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "problemcols = ['Q1: GOING OUT?', 'Q2: GENDER']\n",
    "\n",
    "for column in problemcols:\n",
    "    survey_df_abandrops[column] = [answer if answer != 0 else \"I'd rather not say\" for answer in survey_df_abandrops[column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1: GOING OUT?      Q2: GENDER        \n",
       "No                  Male                  860\n",
       "                    Female                493\n",
       "Yes                 Male                  137\n",
       "                    Female                 82\n",
       "No                  I'd rather not say     51\n",
       "I'd rather not say  Male                   44\n",
       "No                  Other                  18\n",
       "I'd rather not say  Female                  8\n",
       "                    I'd rather not say      8\n",
       "Yes                 I'd rather not say      8\n",
       "                    Other                   3\n",
       "I'd rather not say  Other                   1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_abandrops[['Q1: GOING OUT?', 'Q2: GENDER']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Lolly Categories\n",
    "'Despair', 'Meh' and 'Joy' are reasonably functional, but if I were hired to clean this data set knowing there'd be further exploration, I'd want a slightly better way of scoring and aggregating this information. Just having them as integers seems like a solid idea. We can use some of the tricks employed earlier to convert these values to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_cats = survey_df_abandrops.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoredict = {'DESPAIR': 1,\n",
    "             'MEH': 2,\n",
    "             'JOY': 3}\n",
    "\n",
    "for column in survey_df_cats:\n",
    "    for key, value in scoredict.items():\n",
    "        survey_df_cats[column] = [answer if key != answer else value for answer in survey_df_cats[column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internal ID</th>\n",
       "      <th>Q1: GOING OUT?</th>\n",
       "      <th>Q2: GENDER</th>\n",
       "      <th>Q3: AGE</th>\n",
       "      <th>Q4: COUNTRY</th>\n",
       "      <th>Q5: STATE, PROVINCE, COUNTY, ETC</th>\n",
       "      <th>Q6 | 100 Grand Bar</th>\n",
       "      <th>Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)</th>\n",
       "      <th>Q6 | Any full-sized candy bar</th>\n",
       "      <th>Q6 | Black Jacks</th>\n",
       "      <th>...</th>\n",
       "      <th>Q6 | Twix</th>\n",
       "      <th>Q6 | Vials of pure high fructose corn syrup, for main-lining into your vein</th>\n",
       "      <th>Q6 | Vicodin</th>\n",
       "      <th>Q6 | Whatchamacallit Bars</th>\n",
       "      <th>Q6 | White Bread</th>\n",
       "      <th>Q6 | Whole Wheat anything</th>\n",
       "      <th>Q6 | York Peppermint Patties</th>\n",
       "      <th>Q11: DAY</th>\n",
       "      <th>Click Coordinates (x, y)</th>\n",
       "      <th>Q12: MEDIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90272821</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>USA</td>\n",
       "      <td>NM</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(84, 25)</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90272840</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>us</td>\n",
       "      <td>or</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(75, 23)</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90272841</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>usa</td>\n",
       "      <td>exton pa</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Friday</td>\n",
       "      <td>(70, 10)</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90272852</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(75, 23)</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90272854</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>canada</td>\n",
       "      <td>ontario</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>(55, 5)</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90272858</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(76, 24)</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>90272859</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>53</td>\n",
       "      <td>Us</td>\n",
       "      <td>Wa</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(70, 28)</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>90272865</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>56</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Friday</td>\n",
       "      <td>(73, 24)</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90272866</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>64</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(77, 24)</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90272867</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>43</td>\n",
       "      <td>Murica</td>\n",
       "      <td>California</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Internal ID Q1: GOING OUT? Q2: GENDER  Q3: AGE Q4: COUNTRY  \\\n",
       "0     90272821             No       Male       44        USA    \n",
       "1     90272840             No       Male       40          us   \n",
       "2     90272841             No       Male       23         usa   \n",
       "3     90272852             No       Male       41           0   \n",
       "4     90272854             No       Male       33      canada   \n",
       "5     90272858             No       Male       40      Canada   \n",
       "6     90272859             No     Female       53          Us   \n",
       "7     90272865             No       Male       56      Canada   \n",
       "8     90272866             No       Male       64          US   \n",
       "9     90272867            Yes       Male       43      Murica   \n",
       "\n",
       "  Q5: STATE, PROVINCE, COUNTY, ETC  Q6 | 100 Grand Bar  \\\n",
       "0                               NM                   2   \n",
       "1                               or                   2   \n",
       "2                         exton pa                   3   \n",
       "3                                0                   3   \n",
       "4                          ontario                   3   \n",
       "5                          Ontario                   3   \n",
       "6                               Wa                   2   \n",
       "7                           Quebec                   3   \n",
       "8                               NY                   2   \n",
       "9                       California                   3   \n",
       "\n",
       "   Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)  \\\n",
       "0                                                  1                                        \n",
       "1                                                  1                                        \n",
       "2                                                  1                                        \n",
       "3                                                  1                                        \n",
       "4                                                  1                                        \n",
       "5                                                  1                                        \n",
       "6                                                  1                                        \n",
       "7                                                  2                                        \n",
       "8                                                  2                                        \n",
       "9                                                  1                                        \n",
       "\n",
       "   Q6 | Any full-sized candy bar  Q6 | Black Jacks  ...  Q6 | Twix  \\\n",
       "0                              3                 2  ...          3   \n",
       "1                              3                 2  ...          3   \n",
       "2                              3                 1  ...          3   \n",
       "3                              3                 0  ...          3   \n",
       "4                              3                 1  ...          3   \n",
       "5                              3                 2  ...          3   \n",
       "6                              3                 2  ...          3   \n",
       "7                              3                 2  ...          2   \n",
       "8                              3                 2  ...          2   \n",
       "9                              3                 2  ...          3   \n",
       "\n",
       "   Q6 | Vials of pure high fructose corn syrup, for main-lining into your vein  \\\n",
       "0                                                  1                             \n",
       "1                                                  1                             \n",
       "2                                                  2                             \n",
       "3                                                  1                             \n",
       "4                                                  3                             \n",
       "5                                                  2                             \n",
       "6                                                  1                             \n",
       "7                                                  1                             \n",
       "8                                                  3                             \n",
       "9                                                  1                             \n",
       "\n",
       "   Q6 | Vicodin  Q6 | Whatchamacallit Bars  Q6 | White Bread  \\\n",
       "0             1                          1                 1   \n",
       "1             3                          3                 1   \n",
       "2             3                          3                 1   \n",
       "3             1                          3                 1   \n",
       "4             2                          1                 1   \n",
       "5             1                          2                 1   \n",
       "6             1                          2                 1   \n",
       "7             2                          2                 3   \n",
       "8             3                          1                 1   \n",
       "9             1                          3                 1   \n",
       "\n",
       "   Q6 | Whole Wheat anything  Q6 | York Peppermint Patties  Q11: DAY  \\\n",
       "0                          1                             1    Sunday   \n",
       "1                          1                             1    Sunday   \n",
       "2                          1                             3    Friday   \n",
       "3                          1                             3         0   \n",
       "4                          1                             1    Friday   \n",
       "5                          1                             1    Sunday   \n",
       "6                          1                             2    Sunday   \n",
       "7                          1                             2    Friday   \n",
       "8                          1                             2    Sunday   \n",
       "9                          1                             3    Sunday   \n",
       "\n",
       "   Click Coordinates (x, y)  Q12: MEDIA  \n",
       "0                  (84, 25)     Science  \n",
       "1                  (75, 23)     Science  \n",
       "2                  (70, 10)     Science  \n",
       "3                  (75, 23)     Science  \n",
       "4                   (55, 5)     Science  \n",
       "5                  (76, 24)     Science  \n",
       "6                  (70, 28)     Science  \n",
       "7                  (73, 24)     Science  \n",
       "8                  (77, 24)     Science  \n",
       "9                         0     Science  \n",
       "\n",
       "[10 rows x 112 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_cats.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Country Fields\n",
    "Now for a real challenge! These fields are absolutely abyssmal, filled with inconsistent capitalisation, abbreviations and colloquialisms (such as 'Murica' or 'Merica'). This means we can't just throw a dictionary at it. Let's start with the country field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USA                                                                     515\n",
       "United States                                                           379\n",
       "usa                                                                     158\n",
       "Canada                                                                  104\n",
       "US                                                                       98\n",
       "Usa                                                                      87\n",
       "USA                                                                      53\n",
       "United States of America                                                 43\n",
       "united states                                                            30\n",
       "United States                                                            26\n",
       "us                                                                       23\n",
       "0                                                                        20\n",
       "canada                                                                   19\n",
       "United states                                                            14\n",
       "Us                                                                       10\n",
       "UK                                                                        8\n",
       "United States of America                                                  8\n",
       "U.S.A.                                                                    7\n",
       "United Kingdom                                                            5\n",
       "Germany                                                                   5\n",
       "U.S.                                                                      4\n",
       "united states of america                                                  4\n",
       "Ireland                                                                   3\n",
       "Canada                                                                    3\n",
       "Japan                                                                     3\n",
       "Netherlands                                                               3\n",
       "america                                                                   3\n",
       "u.s.                                                                      2\n",
       "Scotland                                                                  2\n",
       "The United States                                                         2\n",
       "Mexico                                                                    2\n",
       "Unites States                                                             2\n",
       "United State                                                              2\n",
       "Denmark                                                                   2\n",
       "Switzerland                                                               2\n",
       "America                                                                   2\n",
       "US of A                                                                   2\n",
       "Iceland                                                                   1\n",
       "United Statss                                                             1\n",
       "I pretend to be from Canada, but I am really from the United States.      1\n",
       "USA? Hard to tell anymore..                                               1\n",
       "Usa                                                                       1\n",
       "Alaska                                                                    1\n",
       "USAUSAUSA                                                                 1\n",
       "Earth                                                                     1\n",
       "Atlantis                                                                  1\n",
       "endland                                                                   1\n",
       "insanity lately                                                           1\n",
       "Costa Rica                                                                1\n",
       "California                                                                1\n",
       "murrika                                                                   1\n",
       "Europe                                                                    1\n",
       "Fear and Loathing                                                         1\n",
       "u.s.a.                                                                    1\n",
       "United Statea                                                             1\n",
       "China                                                                     1\n",
       "New York                                                                  1\n",
       "Taiwan                                                                    1\n",
       "united States                                                             1\n",
       "CANADA                                                                    1\n",
       "Greece                                                                    1\n",
       "Australia                                                                 1\n",
       "Narnia                                                                    1\n",
       "United staes                                                              1\n",
       "The United States of America                                              1\n",
       "Pittsburgh                                                                1\n",
       "USA USA USA!!!!                                                           1\n",
       "cascadia                                                                  1\n",
       "subscribe to dm4uz3 on youtube                                            1\n",
       "spain                                                                     1\n",
       "U.S.                                                                      1\n",
       "North Carolina                                                            1\n",
       "U S                                                                       1\n",
       "Trumpistan                                                                1\n",
       "Murica                                                                    1\n",
       "USa                                                                       1\n",
       "Canae                                                                     1\n",
       "Ahem....Amerca                                                            1\n",
       "UAE                                                                       1\n",
       "USSA                                                                      1\n",
       "N. America                                                                1\n",
       "Korea                                                                     1\n",
       "A                                                                         1\n",
       "canada                                                                    1\n",
       "United Sates                                                              1\n",
       "South Korea                                                               1\n",
       "I don't know anymore                                                      1\n",
       "france                                                                    1\n",
       "'merica                                                                   1\n",
       "u s a                                                                     1\n",
       "France                                                                    1\n",
       "United Stated                                                             1\n",
       "Canada`                                                                   1\n",
       "Can                                                                       1\n",
       "New Jersey                                                                1\n",
       "Name: Q4: COUNTRY, dtype: int64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "survey_df_cats['Q4: COUNTRY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes! OK, Here's the current plan:\n",
    "1. Make everything upper case to cut a few inconsistencies in a broad sweep.\n",
    "2. Cut all punctuation and spaces from each country.\n",
    "3. Paste in a dictionary of ISO3166 country codes. Source: https://gist.github.com/carlopires/1261951/d13ca7320a6abcd4b0aa800d351a31b54cefdff4\n",
    "4. Make the dictionary all uppercase.\n",
    "5. Remove all spaces from existing dictionary values.\n",
    "6. Append other common terms to dictionary values (eg 'US').\n",
    "7. Loop through the dictionary and replace each value with ISO country codes, taking care to use '==' instead of 'in' to account for cases where new values exist in other countries (eg 'US' can be found in the word 'AUSTRALIA', so we need an exact match).\n",
    "8. Celebrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_countryfix = survey_df_cats.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Personal\\Education\\Programming\\Anaconda1\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "survey_df_countryfix['Q4: COUNTRY'] = [str(country).upper() for country in survey_df_countryfix['Q4: COUNTRY']]\n",
    "\n",
    "for ind, country in enumerate(survey_df_countryfix['Q4: COUNTRY']):\n",
    "    survey_df_countryfix['Q4: COUNTRY'].iloc[ind] = ''.join([char.replace(' ', '') for char in survey_df_countryfix['Q4: COUNTRY'].iloc[ind] if char not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_isodict import ISO3166\n",
    "\n",
    "countrydict = ISO3166.copy()\n",
    "sanitised_countries = [str(country).upper().replace(' ', '') for country in countrydict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, key in enumerate(countrydict.keys()):\n",
    "    countrydict[key] = sanitised_countries[ind]\n",
    "\n",
    "# Given the data is static, I don't mind manually updating the dictionary with a few synonyms it missed.\n",
    "countrydict['US'] = ['UNITEDSTATESOFAMERICA', 'UNITEDSTATES', 'USA', 'US', 'THEUNITEDSTATES', 'AMERICA']\n",
    "countrydict['GB'] = ['SCOTLAND', 'UK', 'UNITEDKINGDOM']\n",
    "countrydict['KR'] = ['SOUTHKOREA', 'REPUBLICOFSOUTHKOREA', 'KOREA']\n",
    "countrydict['AE'] = 'UAE'\n",
    "countrydict['TW'] = ['TAIWANPROVINCEOFCHINA', 'TAIWAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNITEDSTATESOFAMERICA',\n",
       " 'UNITEDSTATES',\n",
       " 'USA',\n",
       " 'US',\n",
       " 'THEUNITEDSTATES',\n",
       " 'AMERICA']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countrydict['US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, country in enumerate(survey_df_countryfix['Q4: COUNTRY']):\n",
    "    for key, values in countrydict.items():\n",
    "        if isinstance(values, list) == True:\n",
    "            for value in values:\n",
    "                if value == country:\n",
    "                    survey_df_countryfix['Q4: COUNTRY'].iloc[ind] = key\n",
    "        else:\n",
    "            if values == country:\n",
    "                survey_df_countryfix['Q4: COUNTRY'].iloc[ind] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US                                                       1475\n",
       "CA                                                        129\n",
       "0                                                          20\n",
       "GB                                                         15\n",
       "DE                                                          5\n",
       "IE                                                          3\n",
       "NL                                                          3\n",
       "JP                                                          3\n",
       "UNITEDSTATE                                                 2\n",
       "FR                                                          2\n",
       "USAUSAUSA                                                   2\n",
       "CH                                                          2\n",
       "UNITESSTATES                                                2\n",
       "KR                                                          2\n",
       "USOFA                                                       2\n",
       "DK                                                          2\n",
       "MX                                                          2\n",
       "NEWJERSEY                                                   1\n",
       "UNITEDSTATSS                                                1\n",
       "IS                                                          1\n",
       "EUROPE                                                      1\n",
       "CANAE                                                       1\n",
       "TRUMPISTAN                                                  1\n",
       "ES                                                          1\n",
       "PITTSBURGH                                                  1\n",
       "INSANITYLATELY                                              1\n",
       "TW                                                          1\n",
       "NAMERICA                                                    1\n",
       "AHEMAMERCA                                                  1\n",
       "NARNIA                                                      1\n",
       "CAN                                                         1\n",
       "UNITEDSATES                                                 1\n",
       "IDONTKNOWANYMORE                                            1\n",
       "UNITEDSTATED                                                1\n",
       "NORTHCAROLINA                                               1\n",
       "CN                                                          1\n",
       "ALASKA                                                      1\n",
       "FEARANDLOATHING                                             1\n",
       "AE                                                          1\n",
       "CR                                                          1\n",
       "UNITEDSTATEA                                                1\n",
       "MERICA                                                      1\n",
       "ENDLAND                                                     1\n",
       "MURICA                                                      1\n",
       "THEUNITEDSTATESOFAMERICA                                    1\n",
       "NEWYORK                                                     1\n",
       "CASCADIA                                                    1\n",
       "EARTH                                                       1\n",
       "USSA                                                        1\n",
       "AU                                                          1\n",
       "USAHARDTOTELLANYMORE                                        1\n",
       "A                                                           1\n",
       "SUBSCRIBETODM4UZ3ONYOUTUBE                                  1\n",
       "CALIFORNIA                                                  1\n",
       "IPRETENDTOBEFROMCANADABUTIAMREALLYFROMTHEUNITEDSTATES       1\n",
       "ATLANTIS                                                    1\n",
       "GR                                                          1\n",
       "UNITEDSTAES                                                 1\n",
       "MURRIKA                                                     1\n",
       "Name: Q4: COUNTRY, dtype: int64"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_countryfix['Q4: COUNTRY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed ISO conversions: 41\n",
      "Successful ISO conversions: 1651\n",
      "2.48% fail rate.\n"
     ]
    }
   ],
   "source": [
    "failures = len([country for country in survey_df_countryfix['Q4: COUNTRY'] if len(country) > 2])\n",
    "successes = len([country for country in survey_df_countryfix['Q4: COUNTRY'] if len(country) == 2])\n",
    "\n",
    "print(f\"Failed ISO conversions: {failures}\")\n",
    "print(f\"Successful ISO conversions: {successes}\")\n",
    "print(f\"{round((failures/ successes) * 100, 2)}% fail rate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decent, but could be better. Given this is a static data set that won't be run again, I'm OK with having slapped a variety of synonyms into a dictionary. In a professional environment where this exercise bore repeating, I'd restrict answers to a predetermiend list rather than free jazz, as this is a disaster. As for responses like 'Murrika', I don't think it's cost effective to try capturing these, as it'd probably take some dark NLP magic all for the sake of two or three aberrant responses.\n",
    "\n",
    "So let's just get the index of each trouble row and replace each one with 'US', because that has the highest likelihood of being correct given Americans are vastly overrepresented in the results already. We can correct any cases where this assumption is wrong afer we've cleaned the states field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrydrop = [ind for ind, country in enumerate(survey_df_countryfix['Q4: COUNTRY']) if len(country) > 2]\n",
    "survey_df_countryfix['Q4: COUNTRY'] = survey_df_countryfix['Q4: COUNTRY'].drop(countrydrop)\n",
    "survey_df_countryfix['Q4: COUNTRY'].replace({np.nan: 'US', '0': 'US'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    1536\n",
       "CA     129\n",
       "GB      15\n",
       "DE       5\n",
       "IE       3\n",
       "JP       3\n",
       "NL       3\n",
       "CH       2\n",
       "MX       2\n",
       "FR       2\n",
       "DK       2\n",
       "KR       2\n",
       "GR       1\n",
       "AE       1\n",
       "CN       1\n",
       "IS       1\n",
       "AU       1\n",
       "ES       1\n",
       "TW       1\n",
       "CR       1\n",
       "A        1\n",
       "Name: Q4: COUNTRY, dtype: int64"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df_countryfix['Q4: COUNTRY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning State Fields"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dde02ba5f02bed1806cc8e85d7502b2a49e870f028b658100d04c0f04704b452"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
